# 1. 모델의 최대 성능 끌어내기

## 1. 하이퍼파라미터 최적화

- 일련의 하이퍼파라미터 선택
- 선택된 하이퍼파라미터로 모델 생성
- 훈련 데이터에 학습 → 검증 데이터에서 성능 측정
- 다음으로 시도할 하이퍼파라미터 선택
- 테스트 데이터 → 성능 측정
- 베이즈 최적화(Bayesian Optimization)
- 유전 알고리즘(Genetic Algorithms)
- 간단한 랜덤 탐색(Random Search)
- KerasTuner : 하이퍼파라미터 튜닝을 쉽게 수행할 수 있는 도구
    - 일련의 하이퍼파라미터 값 선택
    - 모델 구축 함수 호출 → 모델 생성
    - 모델 훈련 → 평가 결과 기록
    - 사전에 정의된 탐색 공간(Premade Search Space) 제공
- AutoML

## 2. 모델 앙상블(Model Ensemble)

- 여러 개의 다른 모델의 예측을 합쳐 더 좋은 예측을 만듦
- 독립적으로 훈련된 다른 종류의 잘 동작하는 모델이 각기 다른 장점을 가지고 있다는 가정 바탕
- 검증 데이터에서 학습된 가중치를 사용하여 가중 평균함
- 좋은 앙상블 가중치 → 랜덤 서치, 넬더-미드 알고리즘

# 2. 대규모 모델 훈련

## 1. 혼합 정밀도로 GPU에서 훈련 속도 높이기

- 혼합 정밀도 훈련(Mixed-Precision Training)
    - 반정밀도(Half Precision) : 16비트에 저장, float16
    - 단정밀도(Single Precision) : 32비트에 저장, float32
    - 배정밀도(Double Precision) : 64비트에 저장, float64

## 2. 다중 GPU 훈련

- 데이터 병렬화(Data Parallelism) : 하나의 모델이 여러 개의 장치 또는 여러 대의 머신에 복제
- 모델 병렬화(Model Parallelism) : 한 모델의 각기 다른 부분이 여러 장치에서 실행되면서 동시에 하나의 데이터 배치 처리
- 2개 이상의 GPU 활용
    - 2 ~ 4개의 GPU를 한 컴퓨터에 설치 → CUDA 드라이버, cnDNN
    - 구글 클라우드, Azure, AWS 다중 GPU 가상 머신 임대
- 단일 호스트, 다중 장치 동기 훈련(Single-host Multi-device Synchronous Training)
    - 미러링된 분산 전략
    - 데이터셋 → 배치 데이터 추출
    - 4개의 서브 배치 분할 → 글로벌 배치 크기 매우 큼
    - 하나의 로컬 배치를 자신의 장치에서 독립적으로 처리, 정방향/역방향 패스 실행
    - 가중치 델타 → 4개의 복제 모델로부터 효율적으로 수집되어 글로벌 델타 생성
    - 2개의 GPU → 속도 2배 증가
    - 4개의 GPU → 속도 3.8배 증가
    - 8개의 GPU → 속도 7.3배 증가

## 3. TPU 훈련(Tensor Processing Unit)

- 구글 TPU : 딥러닝 워크플로를 위해 특별하게 설계된 전문 하드웨어, 단일 목적 칩
- TPU V2 : NVIDIA P100 GPU 15배
- 평균적으로 GPU보다 3배 이상 비용 효율적
- 스텝 융합(Step Fusing) : TPU 실행 스텝마다 여러 훈련 스텝 실행