# 1. 합성곱 신경망(Convolutional Neural Network)

- 기본적인 Conv Net : Conv2D + MaxPooling2D 층을 쌓아 올림
    - Conv2D, MaxPooling2D 출력 : (height, width, channels) 크기 랭크-3 텐서
    - 높이, 너비 차원 → 모델이 깊어질수록 작아짐

## 1. 합성곱 연산

- Dense 층 → 입력 특성 공간에 있는 전역 패턴 학습
- 합성곱 층 → 지역 패턴 학습
- ConvNet 성질
    - 학습된 패턴은 평행 이동 불변성을 가짐
    - 패턴의 공간적 계층 구조 학습 가능
- 특성 맵(랭크-3 텐서)에 적용
    - 2개의 공간 축 + 깊이 축으로 구성
    - 깊이 축에 있는 각 차원 : 하나의 특성
    - 랭크-2 텐서 :  입력에 대한 필터 응답을 나타내는 2D 공간상의 맵
    - 입력 특성 맵 → 작은 패치 추출 → 출력 특성 맵
    - 필터 : 입력 데이터의 어떤 특성 인코딩
    - 특성 맵 출력 → 입력에 대한 필터의 응답 맵
- 합성곱 정의
    - 입력으로부터 뽑아낼 패치의 크기 : 전형적으로 3 * 3, 5 * 5 사용
    - 특성 맵의 출력 깊이 : 합성곱으로 계산할 필터 개수
- 3D 입력 특성 맵 위를 윈도우가 슬라이딩 → 모든 위치에서 3D 특성 패치 추출
- 합성곱 커널(Convolution Kernel) : 하나의 학습된 가중치 행렬
- 출력 높이, 너비 → 입력 높이, 너비와 다를 수 있음
    - 경계 문제, 입력 특성 맵에 패딩 추가
    - 스트라이드의 사용 여부
- 패딩(Padding)
    - 입력과 동일한 높이와 너비를 가진 출력 특성 맵 획득 가능
    - 입력 특성 맵의 가장자리에 적절한 개수의 행, 열 추가
    - `padding` 매개변수 : `valid` , `same`
- 스트라이드
    - 두 번의 연속적인 윈도우 사이의 거리
    - 기본값 1
    - 스트라이드 2 → 특성 맵의 너비, 높이가 2의 배수로 다운샘플링

## 2. 최대 풀링 연산

- 강제적으로 특성 맵을 다운샘플링
- 입력 특성 맵 → 윈도우에 맞는 패치 추출, 각 채널별 최대값 출력
- 다운샘플링 → 처리할 특성 맵의 가중치 개수 감소
- 연속적인 합성곱 층 → 커진 윈도우를 바라봄 → 필터의 공간적 계층 구조 구성
- 평균 풀링(Average Pooling) : 입력 패치 채널별 평균값을 계산하여 변환
- 조밀한 특성 맵 → 작은 패치에 대해 최대로 활성화된 특성 선택

# 2. 소규모 데이터셋에서 밑바닥부터 ConvNet 훈련

## 1. 작은 데이터셋 문제에서 딥러닝의 타당성

- 지역적이고 평행 이동으로 변하지 않는 특성 학습
- 다목적 → 특성 재사용 가능

## 2. 데이터 내려받기

- `shutil` 패키지 → 디렉터리 구조 생성

## 3. 모델 만들기

- 특성 맵 깊이 → 점진적 증가
- 특성 맵 크기 → 점진적 감소

## 4. 데이터 전처리

- 데이터 → 네트워크 주입 전 부동 소수점 타입 텐서로 전처리 필요
- JPEG 파일
    - 사진 파일 읽기
    - JPEG 콘텐츠 → RGB 픽셀 값 디코딩
    - 부동 소수점 타입 텐서 변환
    - 동일한 크기 이미지 변환
    - 배치 묶기
- `image_dataset_from_directory()` : 사진 자동 처리 유틸리티

## 5. 데이터 증식(Data Augmentation)

- 기존 훈련 샘플 → 더 많은 훈련 데이터 생성
- 여러 가지 랜덤한 변환 적용
- 모델 시작 부분 → 여러 개의 데이터 증식 층 추가 가능
- `RandomFlip('horizontal')` : 랜덤하게 50% 이미지를 수평으로 뒤집음
- `RandomRotation(0.1)` : -10% ~ +10% 범위 내에서 랜덤한 값만큼 입력 이미지 회전
- `RandomZoom(0.2)` : -20% ~ +20% 범위 내에서 랜덤한 비율만큼 이미지 확대/축소
- 랜덤한 이미지 증식 층 → 추론할 때는 동작하지 않음

# 3. 사전 훈련된 모델 활용

- 사전 훈련된 모델(Pretrained Model) : 대규모 이미지 분류 문제를 위해 대량의 데이터셋에서 미리 훈련된 모델
- 실제 세상에 대한 일반적인 모델로 효율적인 역할 수행 가능
- 작은 데이터셋을 가진 문제에도 딥러닝 효율적으로 작동 가능
- VGG, ResNet, Inception, Xception

## 1. 사전 훈련된 모델을 사용한 특성 추출

- 사전 학습된 모델 → 새로운 샘플에서 흥미로운 특성 뽑아냄
- ConvNet 특성 맵 : 이미지에 대한 일반적인 콘셉트의 존재 여부 기록
- `keras.applications` 모듈
    - Xception
    - ResNet
    - MobileNet
    - EfficientNet
    - DenseNet
- 데이터 증식 사용 → 합성곱 기반 층 동결 필요

## 2. 사전 훈련된 모델 미세 조정

- 특성 추출에 사용했던 동결 모델의 상위 층 몇 개를 동결에서 해제하고 모델에 새로 추가한 층과 함께 훈련
- 사전 훈련 기반 네트워크 위에 새로운 네트워크 추가
- 기반 네트워크 동결
- 새로 추가한 네트워크 훈련
- 기반 네트워크에서 일부 층 동결 해제
- 동결 해제한 층과 새로 추가한 층 함께 훈련