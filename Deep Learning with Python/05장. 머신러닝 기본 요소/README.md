# 1. 일반화 : 머신러닝 목표

- 최적화(Optimization) : 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조정하는 과정
- 일반화(Generalization) : 훈련된 모델이 이전에 본 적 없는 데이터에서 얼마나 잘 수행되는지 의미
- 최적화, 일반화 균형 맞추기 중요

## 1. 과소적합, 과대적합

- 과소적합(Underfitting) : 훈련 데이터의 손실이 낮아질수록 테스트 데이터의 손실도 낮아짐
- 과대적합 : 훈련 데이터에서 훈련을 특정 횟수 반복하고 난 후에 일반화 성능이 더 이상 높아지지 않으며 검증 세트의 성능이 멈추고 감소되기 시작하는 것
    - 잡음 섞인 데이터
    - 불확실한 특성
    - 드문 특성과 가짜 상관관계
- 특성 선택(Feature Selection) : 가용한 각 특성에 대해 어떤 유용성 점수 계산

## 2. 딥러닝에서 일반화의 본질

- 표현 능력이 충분 → 어떤 것에도 맞추도록 훈련 가능
- 매니폴드(Manifold) : 선형 공간과 비슷하게 보이는 부모 공간의 저차원 부분 공간
- 매니폴드 가설 : 실제 사상의 모든 데이터가 고차원 공간 안에 있는 저차원 매니폴드에 놓여 있다고 가정
    - 머신러닝 모델 → 가능한 입력 공간 안에서 비교적 간단하고 저차원이며 매우 구조적인 부분 공간만 학습
    - 두 입력 사이를 보간하는 것이 항상 가능
- 지역 일반화(Local Generalization) : 이전에 본 것과 매우 가까운 것을 이해하는 데 도움을 줌
- 궁극 일반화(Extreme Generalization) : 보간 + 인지 메커니즘
- 초기 상태 → 점진적인 데이터 맞춤 → 과도기적 최적적합 → 과대적합, 완벽한 훈련 손실
- 모델 향상 → 더 좋고 더 많은 데이터에서 훈련

# 2. 머신러닝 모델 평가

## 1. 훈련, 검증, 테스트 세트

- 하이퍼파라미터(Hyperparameter) : 층이나 층의 유닛 개수를 선택하는 파라미터
- 정보 누설(Information Leak) : 검증 세트의 모델 성능에 기반하여 모델의 하이퍼파라미터를 조정할 때마다 검증 데이터에 관한 정보가 모델로 새는 것
- 단순 홀드아웃 검증(Hold-out Validation) : 데이터의 일정량을 테스트 세트로 떼어두는 것
- K-Fold 교차 검증(K-Fold Cross Validation) : 데이터를 동일한 크기를 가진 K개의 분할로 나눠 모델을 훈련하고 점수를 평균한 것
- 셔플링(Shuffling)을 사용한 반복 K-Fold 교차 검증 : 비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할 때 사용

## 2. 상식 수준의 기준점 넘기

- 작업 시작 전 넘어야 할 간단한 기준점 선점 필요
- 단순한 해결책보다 좋은 해결 모델 필요

## 3. 모델 평가에 대해 유념해야 할 점

- 대표성 있는 데이터
- 시간의 방향
- 데이터 중복

# 3. 훈련 성능 향상하기

- 과대적합 → 최적적합 모델
    - 훈련이 되지 않음
    - 훈련은 잘 시작되었지만 모델이 의미 있는 일반화를 달성하지 못함
    - 시간이 지남에 따라 훈련, 검증 손실이 모두 줄어들고 기준점을 넘어설 수 있지만 과대적합 되지 않음

## 1. 경사 하강법의 핵심 파라미터 튜닝

- 랜덤한 데이터 → 모델 훈련 가능
- 옵티마이저 선택, 모델 가중치 초기값 분포, 학습률, 배치 크기 설정 필요
- 나머지 파라미터 고정, 학습률, 배치 크기 튜닝

## 2. 구조에 대해 더 나은 가정하기

- 입력 데이터에 타깃 예측을 위한 정보가 충분하지 않음
- 현재 사용하는 모델의 종류가 문제에 적합하지 않음

## 3. 모델 용량 늘리기

- 모델 표현 능력(Representational Power) 부족 → 과대적합 불가능

# 4. 일반화 성능 향상하기

## 1. 데이터셋 큐레이션

- 데이터가 충분한지 확인
- 레이블 할당 에러 최소화
- 데이터 정재 및 누락된 값 처리
- 특성 선택

## 2. 특성 공학(Feature Engineering)

- 데이터와 머신러닝 알고리즘에 관한 지식을 사용하는 단계
- 데이터 주입 전 하드코딩된 변환 적용 → 더 잘 수행되는 알고리즘
- 특성을 더 간단한 방식으로 표현하여 문제를 쉽게 만듦

## 3. 조기 종료 사용

- 훈련 손실에 최소값에 도달하기 훨씬 전에 훈련 중단
- 과소적합, 과대적합 사이 정확한 경계 → 일반화 성능 향상

## 4. 모델 규제(Regularization)

- 훈련 데이터에 완벽하게 맞추려는 모델의 능력을 적극적으로 방해하는 일련의 모범 사례
- 모델 검증 점수 향상
- 오캄의 면도날(Occam’s Razor) : 어떤 것에 대한 두 가지의 설명이 있다면 더 적은 가정이 필요한 간단한 설명이 옳을 것임
- 가중치 규제(Weight Regularization) : 모델의 복잡도에 제한을 두어 가중치가 작은 값을 가지도록 강제하는 것
    - L1 규제 : 가중치 절댓값에 비례하는 비용 추가
    - L2 규제 : 가중치 제곱에 비례하는 비용 추가, 가중치 감쇠(Weight Decay)
- 드롭아웃(Dropout) : 훈련하는 동안 무작위로 층의 출력 특성을 일부 제외시키는 것
- 일반화 성능 극대화 & 과대적합 방지
    - 훈련 데이터 증가
    - 더 나은 특성 개발
    - 네트워크 용량 감소
    - 가중치 규제 추가
    - 드롭아웃 추가