# 1. 텐서플로(Tensorflow)

- 구글에서 만든 파이썬 기반 무료 오픈 소스 머신러닝 플랫폼
- 미분 가능한 어떤 표현식에 대해서도 자동으로 그레이디언트 계산 가능
- CPI, GPU, TPU 실행 가능
- 텐서플로에서 정의한 계산 → 여러 머신에 쉽게 분산 가능
- 다른 런타임에 맞게 변환 가능

# 2. 케라스(Keras)

- 텐서플로 위에 구축된 파이썬용 딥러닝 API
- 딥러닝 개발 → 층, 모델, 옵티마이저, 손실, 측정 지표 등

# 3. 케라스와 텐서플로의 역사

- 케라스 : 2015년 3월 릴리스
    - 2015년 말 → 멀티백앤드 구조로 리팩터링
    - 2017년 → CNTK, MXNet 새로운 백엔드 옵션 추가
- 텐서플로 : 2015년 11월 릴리스
    - 2017년 말 → 대부분 케라스 사용
    - 2018년 → 케라스 공식 고수준 API 채택
    - 2019년 9월 → 텐서플로 2.0 릴리스

# 4. 딥러닝 작업 환경 설정

- 코랩
- NVIDIA GPU 사용
- 구글 클라우드, AWS EC2 GPU 인스턴스
- 주피터 노트북 → 권장하는 딥러닝 실험 도구

# 5. 텐서플로 시작하기

- 모든 현대적인 머신러닝의 기초 인프라인 저수준 텐서 연산 → 텐서플로 API
    - 텐서 : 신경망의 상태를 저장하는 특별한 텐서
    - 덧셈, relu, matmul 등 텐서 연산
    - 역전파 : 수학 표현식의 그레이디언트 계산 방법
- 고수준 딥러닝 개념 → 케라스 API
    - 층 : 모델 구성
    - 손실 함수 : 학습에 사용하는 피드백 신호 정의
    - 옵티마이저 : 학습 진행 방법 결정
    - 측정 지표 : 정확도 등 모델 성능 평가
    - 훈련 루프 : 미니 배치 확률적 경사 하강법 수행

## 1. 상수 텐서와 변수

- 텐서 초기값 필요
- 텐서플로 텐서 → 값 할당 불가
- `tf.Variable` : 수정 가능한 상태 관리 클래스
- `assign` : 변수 상태 수정
    - `assign_add()` : +=
    - `assign_sub()` : -=

## 2. 텐서 연산 : 텐서플로에서 수학 계산

- 수학 공식 표현 → 연산 모두 바로 실행
- 즉시 실행 모드(Eager Execution) : 언제든지 현재 결과값 출력 가능

## 3. GradientTape API

- 미분 가능한 표현 → 그레이디언트 계산 가능
- 훈련 가능한 변수 추적

# 6. 신경망의 구조 : 핵심 Keras API

## 1. 층(Layer) : 딥러닝 구성 요소

- 하나 이상의 텐서를 입력으로 받고 하나 이상의 텐서를 출력하는 데이터 처리 모듈
- 대부분 가중치(Weight)라는 층의 상태 가짐 → 확률적 경사 하강법으로 학습되는 하나 이상의 텐서
- 랭크-2 텐서 → 밀집 연결 층(Densely Connected Layer) 처리, 완전 연결 층(Fully Connected Layer), 밀집 층(Dense Layer)
- 랭크-3 텐서 → 순환 층(Recurrent Layer), 1D 합성곱 층(Convolution Layer) 처리
- 랭크-4 텐서 → 2D 합성곱 층 처리
- 케라스 → Layer 또는 Layer와 밀접하게 상호작용
    - Layer : 상태(가중치)와 연산(정방향 패스)을 캡슐화한 객체
    - 가중치 → `build()` 메서드 정의
    - 연산 → `call()` 메서드 정의
- 층 호환(Layer Compatibility) : 모든 층이 특정 크기의 입력 텐서만 받고 특정 크기의 출력 텐서만 반환

## 2. 층에서 모델로

- 네트워크 구조
    - 2개의 가지를 가진 네트워크
    - 멀티헤드 네트워크
    - 잔차 연결(Residual Connection)
- 모델 생성 방법
    - 직접 Model 클래스의 서브클래스 생성
    - 함수형 API 사용
- 모델 구조 : 가설 공간(Hypothesis Space) 정의
- 네트워크 구조 선택 → 가능성 있는 공간 → 입력 데이터를 출력 데이터로 매핑하는 일련의 특정한 텐서 연산 제한

## 3. 컴파일 단계 : 학습 과정 설정

- 손실 함수(Loss Function) : 훈련 과정에서 최소화할 값, 현재 작업에 대한 성공 척도, 목적 함수
    - CategoricalCrossentropy
    - SparseCategoricalCrossentropy
    - BinaryCrossentropy
    - MeanSquaredError
    - KLDIvergence
    - CosineSimilarity
- 옵티마이저(Optimizer) : 손실 함수를 기반으로 네트워크가 어떻게 업데이트될지 결정
    - SGD(모멘텀 선택 가능)
    - RMSProp
    - Adam
    - Adagrad
- 측정 지표(Metric) : 훈련과 검증 과정에서 모니터링할 성공 척도
    - CategoricalAccuracy
    - SparseCategoricalAccuracy
    - BinaryAccuracy
    - AUC
    - Precision
    - Recall
- `compile()` : 훈련 과정 설정

## 4. 손실 함수 선택하기

- 모든 신경망 → 손실 함수를 최소화하기만 함
- 현명한 목적 함수 선택 필요

## 5. fit() 메서드 이해하기

- 훈련 루프 구현
- 훈련할 데이터(입력, 타깃) : 넘파이 배열, 텐서플로 Dataset 객체 전달
- 훈련 에포크 횟수 : 훈련 루프를 몇 번이나 반복할지 알려줌
- 미니 배치 경사 하강법의 각 에포크에서 사용할 배치 크기 : 가중치 업데이트 단계에서 그레이디언트 계산 시 사용될 훈련 샘플 개수

## 6. 검증 데이터에서 손실과 측정 지표 모니터링

- 훈련 데이터의 일부를 검증 데이터로 떼어 놓음
- `evaluate()` : 훈련 후 검증 손실과 측정 지표 계산

## 7. 추론 : 훈련한 모델 사용하기

- 추론(Inference) : 모델을 사용하여 새로운 데이터에서 예측을 만드는 것
    - `__call__()` 메서드 호출 : 모든 입력 한 번에 처리
    - `predict()` 메서드 호출 : 데이터 → 작은 배치로 순회하여 넘파일 배열로 예측 반환