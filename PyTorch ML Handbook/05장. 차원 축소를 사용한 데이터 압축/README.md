# 1. 주성분 분석(PCA, Principal Component Analysis)을 통한 비지도 차원 축소

## 1. 주성분 분석의 주요 단계

- 특성 사이의 상관관계를 기반으로 데이터에 있는 패턴 파악
- 고차원 데이터에서 분산이 가장 큰 방향을 찾고 좀 더 작거나 같은 수의 차원을 갖는 새로운 부분 공간으로 투영
- d 차원 데이터셋 표준화 전처리 → 공분산 행렬 생성 → 고유 벡터와 고유값으로 분해 → 내림차순 정렬 후 고유 벡터 순위 정렬 → 고유값이 가장 큰 k개 고유 벡터 선택 → 최상위 k개 고유 벡터로 투영 행렬 생성 → d 차원 입력 데이터셋을 k 차원 특성 부분 공간으로 변환

## 2. 주성분 추출 단계

- 데이터 표준화 전처리
- 공분산 행렬 구성
- 공분산 행렬의 고유값, 고유 벡터 구하기
- 고유값 내림차순 정렬 → 고유 벡터 순위 정렬

## 3. 총 분산과 설명된 분산

- 설명된 분산 비율(Explained Variance Ratio)

## 4. 특성 변환

- 고유값이 가장 큰 k개 고유 벡터 선택
- 최상위 k개 고유 벡터로 투영 행렬 생성
- d 차원 입력 데이터셋을 k 차원 특성 부분 공간으로 변환

## 5. 사이킷런의 주성분 분석

- 로딩(Loading) : 원본 특성이 주성분에 얼마나 기여하는가, 고유 벡터에 고유값의 제곱근을 곱함

# 2. 선형 판별 분석을 통한 지도 방식의 데이터 압축

- 선형 판별 분석(LDA, Linear Discrimminant Analysis) : 규제가 없는 모델에서 차원의 저주로 인한 과대적합 정도를 줄이고 계산 효율성을 높이기 위한 특성 추출 기법

## 1. 주성분 분석 vs 선형 판별 분석

- PCA
    - 비지도 학습 알고리즘
- LDA
    - 지도 학습 알고리즘
    - 데이터가 정규 분포라 가정
    - 클래스가 동일한 공분산 행렬을 가지고 훈련 샘플은 서로 통계적으로 독립적이라 가정

## 2. 선형 판별 분석의 내부 동작 방식

- d 차원 데이터셋 표준화 전처리
- 각 클래스에 대해 d 차원 평균 벡터 계산
- 클래스 간 산포 행렬, 클래스 내 산포 행렬 구성
- 고유 벡터, 고유값 계산
- 고유값 내림차순 정렬 → 고유 벡터 순서 정렬
- 고유값이 가장 큰 k개 고유 벡터 → d * k 차원 변환 행렬 구성
- 변환 행렬 → 샘플을 새로운 특성 부분 공간으로 투영

## 3. 산포 행렬 계산

- 코드 작성

## 4. 새로운 특성 부분 공간을 위해 선형 판별 벡터 선택

- 코드 작성

## 5. 새로운 특성 공간으로 샘플 투영

- 코드 작성

## 6. 사이킷런의 LDA

- 코드 작성

# 3. 비선형 차원 축소와 시각화

- t-SNE(t-Distributed Stochastic Neighbor Embedding) : 고차원 데이터셋 → 2, 3차원 시각화

## 1. 비선형 차원 축소를 고려하는 이유는 무엇인가요?

- 매니폴드 학습(Manifold Learning) : 비선형 차원 축소 기법 개발 적용
- 고차원 공간에 포함된 저차원 공간 투영

## 2. t-SNE를 사용한 데이터 시각화

- 코드 작성