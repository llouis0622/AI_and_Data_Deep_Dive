{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch 임포트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 1. 데이터셋 이해 및 문제 정의\n",
    "# - 데이터셋: 패션 MNIST (Fashion MNIST)\n",
    "# - 목표: 주어진 의류 이미지를 10개의 카테고리 중 하나로 분류하는 모델을 구축합니다.\n",
    "# - 문제 유형: 다중 클래스 분류\n",
    "# - 평가 지표: 정확도(Accuracy)\n",
    "\n",
    "# 2. 데이터 로드 및 탐색적 데이터 분석(EDA)\n",
    "\n",
    "# 2.1 데이터 로드 및 전처리\n",
    "# 데이터 변환 정의 (Tensor로 변환 및 정규화)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 훈련 데이터셋 및 테스트 데이터셋 로드\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 데이터 로더 정의\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 클래스 이름 정의\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# 2.2 데이터 샘플 시각화\n",
    "# 첫 번째 배치에서 이미지와 레이블 가져오기\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 이미지 시각화\n",
    "plt.figure()\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray')\n",
    "plt.title(f\"레이블: {labels[0].item()} ({class_names[labels[0]]})\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# 여러 이미지 시각화\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    img = images[i - 1].numpy().squeeze()\n",
    "    label = labels[i - 1]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# 3. 모델 선택 및 설계\n",
    "\n",
    "# 3.1 DNN 모델 설계\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)  # CrossEntropyLoss와 함께 사용하기 위해 LogSoftmax\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# 3.2 CNN 모델 설계\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)  # 출력 채널 32, 커널 크기 3x3\n",
    "        self.pool = nn.MaxPool2d(2, 2)    # 커널 크기 2x2, 스트라이드 2\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 64)  # 입력 차원 계산 필요\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)  # CrossEntropyLoss와 함께 사용하기 위해 LogSoftmax\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # [batch_size, 32, 13, 13]\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # [batch_size, 64, 5, 5]\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# 4. 모델 학습 및 검증\n",
    "\n",
    "# 장치 설정 (GPU 사용 가능 시 GPU 사용)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"사용 중인 장치: {device}\")\n",
    "\n",
    "# 모델 인스턴스 생성 및 장치로 이동\n",
    "dnn_model = DNN().to(device)\n",
    "cnn_model = CNN().to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = nn.NLLLoss()  # CrossEntropyLoss와 LogSoftmax 조합 가능\n",
    "dnn_optimizer = optim.Adam(dnn_model.parameters(), lr=0.001)\n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# 4.1 DNN 모델 학습\n",
    "epochs = 20\n",
    "dnn_train_losses = []\n",
    "dnn_train_accuracies = []\n",
    "dnn_val_losses = []\n",
    "dnn_val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    dnn_model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 이미지 Flatten\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        # 옵티마이저 초기화\n",
    "        dnn_optimizer.zero_grad()\n",
    "        # 순전파\n",
    "        outputs = dnn_model(images)\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        dnn_optimizer.step()\n",
    "        # 통계\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    dnn_train_losses.append(train_loss)\n",
    "    dnn_train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # 검증 데이터로 평가\n",
    "    dnn_model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # 이미지 Flatten\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            outputs = dnn_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_loss = val_loss / len(test_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    dnn_val_losses.append(val_loss)\n",
    "    dnn_val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"DNN Epoch [{epoch+1}/{epochs}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "# 4.2 CNN 모델 학습\n",
    "cnn_train_losses = []\n",
    "cnn_train_accuracies = []\n",
    "cnn_val_losses = []\n",
    "cnn_val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    cnn_model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 옵티마이저 초기화\n",
    "        cnn_optimizer.zero_grad()\n",
    "        # 순전파\n",
    "        outputs = cnn_model(images)\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        cnn_optimizer.step()\n",
    "        # 통계\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    cnn_train_losses.append(train_loss)\n",
    "    cnn_train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # 검증 데이터로 평가\n",
    "    cnn_model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = cnn_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_loss = val_loss / len(test_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    cnn_val_losses.append(val_loss)\n",
    "    cnn_val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"CNN Epoch [{epoch+1}/{epochs}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "# 5. 모델 평가 및 시각화\n",
    "\n",
    "# DNN 모델 정확도 시각화\n",
    "plt.figure()\n",
    "plt.plot(dnn_train_accuracies, label='훈련 정확도')\n",
    "plt.plot(dnn_val_accuracies, label='검증 정확도')\n",
    "plt.title('DNN 모델 정확도')\n",
    "plt.xlabel('에포크')\n",
    "plt.ylabel('정확도 (%)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# CNN 모델 정확도 시각화\n",
    "plt.figure()\n",
    "plt.plot(cnn_train_accuracies, label='훈련 정확도')\n",
    "plt.plot(cnn_val_accuracies, label='검증 정확도')\n",
    "plt.title('CNN 모델 정확도')\n",
    "plt.xlabel('에포크')\n",
    "plt.ylabel('정확도 (%)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 저장 및 배포\n",
    "\n",
    "# 6.1 모델 저장\n",
    "torch.save(dnn_model.state_dict(), 'dnn_fashion_mnist.pth')\n",
    "torch.save(cnn_model.state_dict(), 'cnn_fashion_mnist.pth')\n",
    "\n",
    "# 6.2 모델 로드\n",
    "# DNN 모델 로드\n",
    "loaded_dnn_model = DNN()\n",
    "loaded_dnn_model.load_state_dict(torch.load('dnn_fashion_mnist.pth'))\n",
    "loaded_dnn_model.to(device)\n",
    "\n",
    "# CNN 모델 로드\n",
    "loaded_cnn_model = CNN()\n",
    "loaded_cnn_model.load_state_dict(torch.load('cnn_fashion_mnist.pth'))\n",
    "loaded_cnn_model.to(device)\n",
    "\n",
    "# 6.3 새로운 데이터로 예측\n",
    "# 예시로 테스트 데이터의 첫 번째 이미지 사용\n",
    "loaded_cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    new_image = test_dataset[0][0].unsqueeze(0).to(device)  # 배치 차원 추가\n",
    "    output = loaded_cnn_model(new_image)\n",
    "    _, predicted_label = torch.max(output.data, 1)\n",
    "    predicted_label = predicted_label.item()\n",
    "    actual_label = test_dataset[0][1]\n",
    "\n",
    "print(f\"예측된 레이블: {predicted_label} ({class_names[predicted_label]})\")\n",
    "print(f\"실제 레이블: {actual_label} ({class_names[actual_label]})\")\n",
    "\n",
    "# 이미지 시각화\n",
    "plt.figure()\n",
    "plt.imshow(new_image.cpu().squeeze(), cmap='gray')\n",
    "plt.title(f\"실제 레이블: {class_names[actual_label]}, 예측된 레이블: {class_names[predicted_label]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
