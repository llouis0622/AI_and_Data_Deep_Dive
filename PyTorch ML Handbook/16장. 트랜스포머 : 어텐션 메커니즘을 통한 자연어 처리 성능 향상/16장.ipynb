{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-08T06:43:13.604561Z",
     "start_time": "2024-11-08T06:43:09.584057Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "#  \"Can you help me to translate this sentence\"\n",
    "sentence = torch.tensor(\n",
    "    [0,  # can\n",
    "     7,  # you\n",
    "     1,  # help\n",
    "     2,  # me\n",
    "     5,  # to\n",
    "     6,  # translate\n",
    "     4,  # this\n",
    "     3]  # sentence\n",
    ")\n",
    "sentence"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 7, 1, 2, 5, 6, 4, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:43:19.730668Z",
     "start_time": "2024-11-08T06:43:19.723634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(10, 16)\n",
    "embedded_sentence = embed(sentence).detach()\n",
    "embedded_sentence.shape"
   ],
   "id": "b50d95261cb3400",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:43:26.787136Z",
     "start_time": "2024-11-08T06:43:26.783506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "omega = torch.empty(8, 8)\n",
    "for i, x_i in enumerate(embedded_sentence):\n",
    "    for j, x_j in enumerate(embedded_sentence):\n",
    "        omega[i, j] = torch.dot(x_i, x_j)"
   ],
   "id": "966a3f1716e1ed88",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:43:34.973898Z",
     "start_time": "2024-11-08T06:43:34.971372Z"
    }
   },
   "cell_type": "code",
   "source": "omega_mat = embedded_sentence.matmul(embedded_sentence.T)",
   "id": "df4f1c408059b60d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:43:39.284696Z",
     "start_time": "2024-11-08T06:43:39.281168Z"
    }
   },
   "cell_type": "code",
   "source": "torch.allclose(omega_mat, omega)",
   "id": "756ea3d614579b3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:43:45.406661Z",
     "start_time": "2024-11-08T06:43:45.402002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "attention_weights = F.softmax(omega, dim=1)\n",
    "attention_weights.shape"
   ],
   "id": "4ea1665199362a4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:43:51.071383Z",
     "start_time": "2024-11-08T06:43:51.068070Z"
    }
   },
   "cell_type": "code",
   "source": "attention_weights.sum(dim=1)",
   "id": "66d541f9e8c5f769",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:44:02.380515Z",
     "start_time": "2024-11-08T06:44:02.374953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_2 = embedded_sentence[1, :]\n",
    "context_vec_2 = torch.zeros(x_2.shape)\n",
    "for j in range(8):\n",
    "    x_j = embedded_sentence[j, :]\n",
    "    context_vec_2 += attention_weights[1, j] * x_j\n",
    "context_vec_2"
   ],
   "id": "956e9ef79ebe9a98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
       "        -1.2896e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
       "        -7.1287e-04,  1.2449e+00, -7.8077e-02,  1.2765e+00, -1.4589e+00,\n",
       "        -2.1601e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:44:11.457982Z",
     "start_time": "2024-11-08T06:44:11.454490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_vectors = torch.matmul(attention_weights, embedded_sentence)\n",
    "torch.allclose(context_vec_2, context_vectors[1])"
   ],
   "id": "f9f986b1f6d9ce7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:50:54.406580Z",
     "start_time": "2024-11-08T06:50:54.402383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "d = embedded_sentence.shape[1]\n",
    "U_query = torch.rand(d, d)\n",
    "U_key = torch.rand(d, d)\n",
    "U_value = torch.rand(d, d)"
   ],
   "id": "f43875e48afbca75",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:51:02.212880Z",
     "start_time": "2024-11-08T06:51:02.209377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "query_2 = U_query.matmul(x_2)"
   ],
   "id": "70b60a54b7916f46",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:51:06.155771Z",
     "start_time": "2024-11-08T06:51:06.153397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "key_2 = U_key.matmul(x_2)\n",
    "value_2 = U_value.matmul(x_2)"
   ],
   "id": "13c840ff9b0fbcc9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:51:10.325460Z",
     "start_time": "2024-11-08T06:51:10.322080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "keys = U_key.matmul(embedded_sentence.T).T\n",
    "torch.allclose(key_2, keys[1])"
   ],
   "id": "68eeb1b50d7b4b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:51:15.185864Z",
     "start_time": "2024-11-08T06:51:15.182766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "values = U_value.matmul(embedded_sentence.T).T\n",
    "torch.allclose(value_2, values[1])"
   ],
   "id": "c13c88b33c82a7ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:51:19.829941Z",
     "start_time": "2024-11-08T06:51:19.825679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "omega_23 = query_2.dot(keys[2])\n",
    "omega_23"
   ],
   "id": "f697bcad175829ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.3667)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:51:24.162204Z",
     "start_time": "2024-11-08T06:51:24.158621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "omega_2 = query_2.matmul(keys.T)\n",
    "omega_2"
   ],
   "id": "755d8d181bbca675",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-25.1623,   9.3602,  14.3667,  32.1481,  53.8976,  46.6626,  -1.2131,\n",
       "        -32.9391])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:51:58.443462Z",
     "start_time": "2024-11-08T06:51:58.440210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attention_weights_2 = F.softmax(omega_2 / d ** 0.5, dim=0)\n",
    "attention_weights_2"
   ],
   "id": "a17f783c90956717",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2317e-09, 1.2499e-05, 4.3696e-05, 3.7242e-03, 8.5596e-01, 1.4026e-01,\n",
       "        8.8897e-07, 3.1936e-10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:52:06.948949Z",
     "start_time": "2024-11-08T06:52:06.945392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_vector_2 = attention_weights_2.matmul(values)\n",
    "context_vector_2"
   ],
   "id": "49f033fad4c63815",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2226, -3.4387, -4.3928, -5.2125, -1.1249, -3.3041, -1.4316, -3.2765,\n",
       "        -2.5114, -2.6105, -1.5793, -2.8433, -2.4142, -0.3998, -1.9917, -3.3499])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:58:20.139369Z",
     "start_time": "2024-11-08T06:58:20.134376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "d = embedded_sentence.shape[1]\n",
    "one_U_query = torch.rand(d, d)"
   ],
   "id": "8ff3de799a5d4287",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:58:25.753499Z",
     "start_time": "2024-11-08T06:58:25.750626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "h = 8\n",
    "multihead_U_query = torch.rand(h, d, d)\n",
    "multihead_U_key = torch.rand(h, d, d)\n",
    "multihead_U_value = torch.rand(h, d, d)"
   ],
   "id": "468b7b87e05ce7c5",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:58:54.244598Z",
     "start_time": "2024-11-08T06:58:54.241990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multihead_query_2 = multihead_U_query.matmul(x_2)\n",
    "multihead_query_2.shape"
   ],
   "id": "824b1e6140707a7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:59:03.546514Z",
     "start_time": "2024-11-08T06:59:03.542806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multihead_key_2 = multihead_U_key.matmul(x_2)\n",
    "multihead_value_2 = multihead_U_value.matmul(x_2)\n",
    "multihead_key_2[2]"
   ],
   "id": "b6fdc00dcb044093",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9619, -0.7701, -0.7280, -1.6840, -1.0801, -1.6778,  0.6763,  0.6547,\n",
       "         1.4445, -2.7016, -1.1364, -1.1204, -2.4430, -0.5982, -0.8292, -1.4401])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:59:10.179863Z",
     "start_time": "2024-11-08T06:59:10.176027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stacked_inputs = embedded_sentence.T.repeat(8, 1, 1)\n",
    "stacked_inputs.shape"
   ],
   "id": "9c9b8b3a10380365",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:59:14.754608Z",
     "start_time": "2024-11-08T06:59:14.751345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multihead_keys = torch.bmm(multihead_U_key, stacked_inputs)\n",
    "multihead_keys.shape"
   ],
   "id": "a4c11c52d84b3dfd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:59:21.295250Z",
     "start_time": "2024-11-08T06:59:21.291949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multihead_keys = multihead_keys.permute(0, 2, 1)\n",
    "multihead_keys.shape"
   ],
   "id": "ebec8ef123cbe79",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:59:28.897344Z",
     "start_time": "2024-11-08T06:59:28.893550Z"
    }
   },
   "cell_type": "code",
   "source": "multihead_keys[2, 1]",
   "id": "b43d21cf53e6d4d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9619, -0.7701, -0.7280, -1.6840, -1.0801, -1.6778,  0.6763,  0.6547,\n",
       "         1.4445, -2.7016, -1.1364, -1.1204, -2.4430, -0.5982, -0.8292, -1.4401])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:59:33.605479Z",
     "start_time": "2024-11-08T06:59:33.602929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multihead_values = torch.matmul(multihead_U_value, stacked_inputs)\n",
    "multihead_values = multihead_values.permute(0, 2, 1)"
   ],
   "id": "9906ec22ba024a60",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:59:39.522033Z",
     "start_time": "2024-11-08T06:59:39.519530Z"
    }
   },
   "cell_type": "code",
   "source": "multihead_z_2 = torch.rand(8, 16)",
   "id": "138ce86f3158dbfe",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T06:59:46.911664Z",
     "start_time": "2024-11-08T06:59:46.907624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linear = torch.nn.Linear(8 * 16, 16)\n",
    "context_vector_2 = linear(multihead_z_2.flatten())\n",
    "context_vector_2.shape"
   ],
   "id": "6f3404a79003064e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:29:15.177259Z",
     "start_time": "2024-11-08T07:28:31.530452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(123)\n",
    "generator(\"Hey readers, today is\", max_length=20, num_return_sequences=3)"
   ],
   "id": "106912b3f93bffdf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17048e3811634956a588ffcfbe9a8715"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8737429fdae34df38205e1dccd5b8e1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f95b13ef2de042119d2e8851f53d7f8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4617b644660449ae853f50ffe03090e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82b048bd51134a519b6cdc6c279f418b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87be9a25ccb84ee7acf7050cd076f502"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "398b5a7541c7429a997fe5d78c968a0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hey readers, today is not the last time we'll be seeing one of our favorite indie rock bands\"},\n",
       " {'generated_text': 'Hey readers, today is Christmas. This is not Christmas, because Christmas is so long and I hope'},\n",
       " {'generated_text': \"Hey readers, today is CTA Day!\\n\\nWe're proud to be hosting a special event\"}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:29:21.284195Z",
     "start_time": "2024-11-08T07:29:20.986332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "text = \"Let us encode this sentence\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "encoded_input"
   ],
   "id": "180569dcad8f7a6f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 5756,   514, 37773,   428,  6827]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:29:24.290658Z",
     "start_time": "2024-11-08T07:29:23.148620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2Model\n",
    "\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "output = model(**encoded_input)\n",
    "output['last_hidden_state'].shape"
   ],
   "id": "6272042302836ba2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:33:37.854380Z",
     "start_time": "2024-11-08T07:33:37.840114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NUM_EPOCHS = 3"
   ],
   "id": "6f4ded2fe8766058",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:33:49.383597Z",
     "start_time": "2024-11-08T07:33:45.745765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "url = \"https://github.com/rasbt/machine-learning-book/raw/main/ch08/movie_data.csv.gz\"\n",
    "filename = url.split(\"/\")[-1]\n",
    "\n",
    "with open(filename, \"wb\") as f:\n",
    "    r = requests.get(url)\n",
    "    f.write(r.content)\n",
    "\n",
    "with gzip.open('movie_data.csv.gz', 'rb') as f_in:\n",
    "    with open('movie_data.csv', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ],
   "id": "5f9bdf121bf5e315",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:33:54.514019Z",
     "start_time": "2024-11-08T07:33:53.883623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('movie_data.csv')\n",
    "df.head()"
   ],
   "id": "3e452f92d63b1280",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:34:00.218420Z",
     "start_time": "2024-11-08T07:34:00.215720Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "2f828e0e1c5260fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:34:06.999953Z",
     "start_time": "2024-11-08T07:34:06.996881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_texts = df.iloc[:35000]['review'].values\n",
    "train_labels = df.iloc[:35000]['sentiment'].values\n",
    "\n",
    "valid_texts = df.iloc[35000:40000]['review'].values\n",
    "valid_labels = df.iloc[35000:40000]['sentiment'].values\n",
    "\n",
    "test_texts = df.iloc[40000:]['review'].values\n",
    "test_labels = df.iloc[40000:]['sentiment'].values"
   ],
   "id": "f4672305adc4cf21",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:34:15.501203Z",
     "start_time": "2024-11-08T07:34:15.215667Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')",
   "id": "497ac42305ed555c",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:34:34.285450Z",
     "start_time": "2024-11-08T07:34:21.489487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(list(valid_texts), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)"
   ],
   "id": "6ef964e03764b833",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:34:40.513604Z",
     "start_time": "2024-11-08T07:34:40.509994Z"
    }
   },
   "cell_type": "code",
   "source": "train_encodings[0]",
   "id": "17da3765a5a0a545",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:34:47.920198Z",
     "start_time": "2024-11-08T07:34:47.915308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "valid_dataset = IMDbDataset(valid_encodings, valid_labels)\n",
    "test_dataset = IMDbDataset(test_encodings, test_labels)"
   ],
   "id": "8293da50969b838e",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:34:53.363648Z",
     "start_time": "2024-11-08T07:34:53.360568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ],
   "id": "f767f919443d269d",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:35:03.887021Z",
     "start_time": "2024-11-08T07:35:02.879048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(DEVICE)\n",
    "model.train()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ],
   "id": "a24be5e2c81c3707",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:35:17.428984Z",
     "start_time": "2024-11-08T07:35:17.424756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct_pred, num_examples = 0, 0\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            predicted_labels = torch.argmax(logits, 1)\n",
    "            num_examples += labels.size(0)\n",
    "            correct_pred += (predicted_labels == labels).sum()\n",
    "\n",
    "        return correct_pred.float() / num_examples * 100"
   ],
   "id": "ee0f452dadd945bb",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:57:04.827891Z",
     "start_time": "2024-11-08T07:35:59.700896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss, logits = outputs['loss'], outputs['logits']\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if not batch_idx % 250:\n",
    "            print(f'에포크 : {epoch + 1:04d}/{NUM_EPOCHS:04d} | '\n",
    "                  f'배치 {batch_idx:04d}/{len(train_loader):04d} | '\n",
    "                  f'손실 : {loss:.4f}')\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'훈련 정확도 : '\n",
    "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
    "              f'\\n검증 정확도 : '\n",
    "              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
    "\n",
    "    print(f'소요 시간 : {(time.time() - start_time) / 60:.2f} min')\n",
    "\n",
    "print(f'총 훈련 시간 : {(time.time() - start_time) / 60:.2f} min')\n",
    "print(f'테스트 정확도 : {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ],
   "id": "afd12808e6b9575",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 : 0001/0003 | 배치 0000/2188 | 손실 : 0.6911\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[1;32m      7\u001B[0m labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[0;32m----> 9\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(input_ids, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask, labels\u001B[38;5;241m=\u001B[39mlabels)\n\u001B[1;32m     10\u001B[0m loss, logits \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m], outputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogits\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     12\u001B[0m optim\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:991\u001B[0m, in \u001B[0;36mDistilBertForSequenceClassification.forward\u001B[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    983\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    984\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[1;32m    987\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[1;32m    988\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    989\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m--> 991\u001B[0m distilbert_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistilbert(\n\u001B[1;32m    992\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m    993\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m    994\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mhead_mask,\n\u001B[1;32m    995\u001B[0m     inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds,\n\u001B[1;32m    996\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    997\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m    998\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m    999\u001B[0m )\n\u001B[1;32m   1000\u001B[0m hidden_state \u001B[38;5;241m=\u001B[39m distilbert_output[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# (bs, seq_len, dim)\u001B[39;00m\n\u001B[1;32m   1001\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m hidden_state[:, \u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# (bs, dim)\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:811\u001B[0m, in \u001B[0;36mDistilBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    809\u001B[0m         attention_mask \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones(input_shape, device\u001B[38;5;241m=\u001B[39mdevice)  \u001B[38;5;66;03m# (bs, seq_length)\u001B[39;00m\n\u001B[0;32m--> 811\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer(\n\u001B[1;32m    812\u001B[0m     x\u001B[38;5;241m=\u001B[39membeddings,\n\u001B[1;32m    813\u001B[0m     attn_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m    814\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mhead_mask,\n\u001B[1;32m    815\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m    816\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m    817\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m    818\u001B[0m )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:572\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    564\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    565\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    566\u001B[0m         hidden_state,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    569\u001B[0m         output_attentions,\n\u001B[1;32m    570\u001B[0m     )\n\u001B[1;32m    571\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 572\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m layer_module(\n\u001B[1;32m    573\u001B[0m         hidden_state,\n\u001B[1;32m    574\u001B[0m         attn_mask,\n\u001B[1;32m    575\u001B[0m         head_mask[i],\n\u001B[1;32m    576\u001B[0m         output_attentions,\n\u001B[1;32m    577\u001B[0m     )\n\u001B[1;32m    579\u001B[0m hidden_state \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    581\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:516\u001B[0m, in \u001B[0;36mTransformerBlock.forward\u001B[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001B[0m\n\u001B[1;32m    513\u001B[0m sa_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msa_layer_norm(sa_output \u001B[38;5;241m+\u001B[39m x)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;66;03m# Feed Forward Network\u001B[39;00m\n\u001B[0;32m--> 516\u001B[0m ffn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mffn(sa_output)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[1;32m    517\u001B[0m ffn_output: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_layer_norm(ffn_output \u001B[38;5;241m+\u001B[39m sa_output)  \u001B[38;5;66;03m# (bs, seq_length, dim)\u001B[39;00m\n\u001B[1;32m    519\u001B[0m output \u001B[38;5;241m=\u001B[39m (ffn_output,)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:451\u001B[0m, in \u001B[0;36mFFN.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m apply_chunking_to_forward(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mff_chunk, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_size_feed_forward, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseq_len_dim, \u001B[38;5;28minput\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/pytorch_utils.py:238\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;66;03m# concatenate output at same dimension\u001B[39;00m\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[0;32m--> 238\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m forward_fn(\u001B[38;5;241m*\u001B[39minput_tensors)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:456\u001B[0m, in \u001B[0;36mFFN.ff_chunk\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    454\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin1(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    455\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(x)\n\u001B[0;32m--> 456\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin2(x)\n\u001B[1;32m    457\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(x)\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "del model",
   "id": "8ab8182647c1bb41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T07:59:30.766036Z",
     "start_time": "2024-11-08T07:59:29.894395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(DEVICE)\n",
    "model.train()"
   ],
   "id": "4cf2c88e1239bef0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:02:33.129875Z",
     "start_time": "2024-11-08T08:02:33.059801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")"
   ],
   "id": "e8d7ec37bd466318",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Trainer, TrainingArguments\n\u001B[1;32m      3\u001B[0m optim \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5e-5\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m training_args \u001B[38;5;241m=\u001B[39m TrainingArguments(\n\u001B[1;32m      5\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./results\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      6\u001B[0m     num_train_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m      7\u001B[0m     per_device_train_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[1;32m      8\u001B[0m     per_device_eval_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[1;32m      9\u001B[0m     logging_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./logs\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     10\u001B[0m     logging_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     13\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     14\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     15\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m     16\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39mtrain_dataset,\n\u001B[1;32m     17\u001B[0m )\n",
      "File \u001B[0;32m<string>:128\u001B[0m, in \u001B[0;36m__init__\u001B[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics)\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1641\u001B[0m, in \u001B[0;36mTrainingArguments.__post_init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1635\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m version\u001B[38;5;241m.\u001B[39mparse(version\u001B[38;5;241m.\u001B[39mparse(torch\u001B[38;5;241m.\u001B[39m__version__)\u001B[38;5;241m.\u001B[39mbase_version) \u001B[38;5;241m==\u001B[39m version\u001B[38;5;241m.\u001B[39mparse(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2.0.0\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp16:\n\u001B[1;32m   1636\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1639\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1640\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m is_torch_available()\n\u001B[0;32m-> 1641\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_greater_or_equal_than_2_3)\n\u001B[1;32m   1642\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1643\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmlu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1644\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1645\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1646\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (get_xla_device_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m   1647\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp16 \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp16_full_eval)\n\u001B[1;32m   1648\u001B[0m ):\n\u001B[1;32m   1649\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1650\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1651\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or MLU devices or NPU devices or certain XPU devices (with IPEX).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1652\u001B[0m     )\n\u001B[1;32m   1654\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1656\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m is_torch_available()\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1664\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbf16 \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbf16_full_eval)\n\u001B[1;32m   1665\u001B[0m ):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:2149\u001B[0m, in \u001B[0;36mTrainingArguments.device\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2145\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2146\u001B[0m \u001B[38;5;124;03mThe device used by this process.\u001B[39;00m\n\u001B[1;32m   2147\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2148\u001B[0m requires_backends(\u001B[38;5;28mself\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m-> 2149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setup_devices\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:59\u001B[0m, in \u001B[0;36mcached_property.__get__\u001B[0;34m(self, obj, objtype)\u001B[0m\n\u001B[1;32m     57\u001B[0m cached \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, attr, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 59\u001B[0m     cached \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfget(obj)\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(obj, attr, cached)\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cached\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:2055\u001B[0m, in \u001B[0;36mTrainingArguments._setup_devices\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2053\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_sagemaker_mp_enabled():\n\u001B[1;32m   2054\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available():\n\u001B[0;32m-> 2055\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m   2056\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mACCELERATE_MIN_VERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2057\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease run `pip install transformers[torch]` or `pip install accelerate -U`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2058\u001B[0m         )\n\u001B[1;32m   2059\u001B[0m     AcceleratorState\u001B[38;5;241m.\u001B[39m_reset_state(reset_partial_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   2060\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistributed_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:02:37.253311Z",
     "start_time": "2024-11-08T08:02:35.792485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(\n",
    "        predictions=predictions, references=labels)"
   ],
   "id": "99191ca786af8283",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23ae9d9672e9421dbc7313be31adc1fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:02:51.521222Z",
     "start_time": "2024-11-08T08:02:51.442871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    compute_metrics=compute_metrics,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    optimizers=(optim, None)\n",
    ")\n",
    "\n",
    "trainer.args._n_gpu = 1"
   ],
   "id": "e66683e9771aa4a7",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[53], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m optim \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5e-5\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m training_args \u001B[38;5;241m=\u001B[39m TrainingArguments(\n\u001B[1;32m      4\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./results\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      5\u001B[0m     num_train_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m      6\u001B[0m     per_device_train_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[1;32m      7\u001B[0m     per_device_eval_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[1;32m      8\u001B[0m     logging_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./logs\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      9\u001B[0m     logging_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m\n\u001B[1;32m     10\u001B[0m )\n\u001B[1;32m     12\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[1;32m     13\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     14\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m     optimizers\u001B[38;5;241m=\u001B[39m(optim, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     19\u001B[0m )\n\u001B[1;32m     21\u001B[0m trainer\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39m_n_gpu \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m<string>:128\u001B[0m, in \u001B[0;36m__init__\u001B[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics)\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1641\u001B[0m, in \u001B[0;36mTrainingArguments.__post_init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1635\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m version\u001B[38;5;241m.\u001B[39mparse(version\u001B[38;5;241m.\u001B[39mparse(torch\u001B[38;5;241m.\u001B[39m__version__)\u001B[38;5;241m.\u001B[39mbase_version) \u001B[38;5;241m==\u001B[39m version\u001B[38;5;241m.\u001B[39mparse(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2.0.0\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp16:\n\u001B[1;32m   1636\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1639\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1640\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m is_torch_available()\n\u001B[0;32m-> 1641\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_greater_or_equal_than_2_3)\n\u001B[1;32m   1642\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1643\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmlu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1644\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1645\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1646\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (get_xla_device_type(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCUDA\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m   1647\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp16 \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp16_full_eval)\n\u001B[1;32m   1648\u001B[0m ):\n\u001B[1;32m   1649\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1650\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1651\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or MLU devices or NPU devices or certain XPU devices (with IPEX).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1652\u001B[0m     )\n\u001B[1;32m   1654\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1656\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m is_torch_available()\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1664\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbf16 \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbf16_full_eval)\n\u001B[1;32m   1665\u001B[0m ):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:2149\u001B[0m, in \u001B[0;36mTrainingArguments.device\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2145\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2146\u001B[0m \u001B[38;5;124;03mThe device used by this process.\u001B[39;00m\n\u001B[1;32m   2147\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2148\u001B[0m requires_backends(\u001B[38;5;28mself\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m-> 2149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setup_devices\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:59\u001B[0m, in \u001B[0;36mcached_property.__get__\u001B[0;34m(self, obj, objtype)\u001B[0m\n\u001B[1;32m     57\u001B[0m cached \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, attr, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 59\u001B[0m     cached \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfget(obj)\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(obj, attr, cached)\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cached\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:2055\u001B[0m, in \u001B[0;36mTrainingArguments._setup_devices\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2053\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_sagemaker_mp_enabled():\n\u001B[1;32m   2054\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available():\n\u001B[0;32m-> 2055\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m   2056\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mACCELERATE_MIN_VERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2057\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease run `pip install transformers[torch]` or `pip install accelerate -U`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2058\u001B[0m         )\n\u001B[1;32m   2059\u001B[0m     AcceleratorState\u001B[38;5;241m.\u001B[39m_reset_state(reset_partial_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   2060\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistributed_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:03:11.599069Z",
     "start_time": "2024-11-08T08:03:11.573709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "trainer.train()\n",
    "print(f'총 훈련 시간: {(time.time() - start_time) / 60:.2f} min')"
   ],
   "id": "7745673944a092a2",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 2\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m총 훈련 시간: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m(time\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart_time)\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m60\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m min\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T08:03:13.869333Z",
     "start_time": "2024-11-08T08:03:13.852083Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate()",
   "id": "425c8bf98568e7f5",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[55], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m trainer\u001B[38;5;241m.\u001B[39mevaluate()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "print(f'테스트 정확도: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ],
   "id": "d879bb99c204733f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
