# 1. 파이프라인을 사용한 효율적인 워크플로

## 1. 위스콘신 유방암 데이터셋

- 코드 작성

## 2. 파이프라인으로 변환기와 추정기 연결

- 주성분 분석 → 데이터 압축
- 훈련 데이터셋, 테스트 데이터셋 각각 학습 및 변환 → 하나의 파이프라인 연결

# 2. k-폴드 교차 검증을 사용한 모델 성능 평가

## 1. 홀드아웃 방법(Holdout Method)

- 머신러닝 모델 일반화 성능 추정
- 초기 데이터셋 → 별도의 훈련 데이터셋, 테스트 데이터셋으로 분리
- 훈련 데이터셋 → 여러 가지 모델 훈련 사용
- 검증 데이터셋 → 모델 선택 사용
- 테스트 데이터셋 → 일반화 성능 추정

## 2. k-폴드 교차 검증(k-fold)

- 중복 미허용 훈련 데이터셋 → k개 폴드로 랜덤하게 구분
- k - 1개의 폴드로 훈련, 나머지 폴드로 성능 평가
- 서로 다른 독립적인 폴드에서 얻은 성능 추정 → 모델 평균 성능 계산

# 3. 학습 곡선과 검증 곡선을 사용한 알고리즘 디버깅

## 1. 학습 곡선으로 편향과 분산 문제 분석

- 훈련 데이터셋에 비해 복잡한 모델 → 과대적합
- 서포트 벡터 머신(SVM), 로지스틱 회귀 분류기 → 규제 강도 감소

## 2. 검증 곡선으로 과대적합과 과소적합 조사

- 샘플 크기의 함수 → 모델 파라미터 값의 함수로 그림

# 4. 그리드 서치를 사용한 머신러닝 모델 세부 튜닝

## 1. 그리드 서치를 사용한 하이퍼파라미터 튜닝

- 리스트로 지정된 여러 가지 하이퍼파라미터 값 전체 모두 조사
- 값의 모든 조합에 대해 모델 성능 평가 → 최적의 조합 찾기

## 2. 랜덤 서치로 하이퍼파라미터 설정을 더 넓게 탐색하기

- 랜덤 서치 : 분포에서 랜덤하게 하이퍼파라미터 설정 샘플링

## 3. SH 방식을 사용한 자원 효율적인 하이퍼파라미터 탐색

- 후보 설정 집합에서 하나의 설정이 남을 때까지 적합하지 않은 하이퍼파라미터 설정 연속적으로 버림
- 랜덤 샘플링으로 후보 설정 집합 샘플링 → 훈련 데이터의 일부로 모델 훈련 → 예측 성능 기준으로 하위 50% 버림 → 가용 자원 중가 후 반복

## 4. 중첩 교차 검증을 사용한 알고리즘 선택

- 바깥쪽 k-폴드 교차 검증 루프가 데이터를 훈련 폴드, 테스트 폴드로 나눔
- 안쪽 루프 훈련 폴드에서 k-폴드 교차 검증 수행 → 모델 선택

# 5. 여러 가지 성능 평가 지표

## 1. 오차 행렬(Confusion Matrix)

- 진짜 양성(TP, True Positive)
- 진짜 음성(TN, True Negative)
- 거짓 양성(FP, False Positive)
- 거짓 음성(FN, False Negative)

## 2. 분류 모델의 정밀도와 재현율 최적화

- ERR = FP + FN / FP + FN + TP + TN
- ACC = 1 - ERR
- FPR = FP / FP + TN
- TPR = TP / FN + TP
- REC = TP / FN + TP
- PRE = TP / TP + FP
- F1 = 2 * (PRE * REC) / PRE + REC

## 3. ROC 곡선 그리기

- 분류기의 임계값을 바꾸어 가며 계산된 FPR과 TPR 점수를 기반으로 분류 모델 선택

## 4. 다중 분류의 성능 지표

- 코드 작성

## 5. 불균형한 클래스 다루기

- 코드 작성