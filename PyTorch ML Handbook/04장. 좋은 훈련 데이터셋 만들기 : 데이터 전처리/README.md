# 1. 누락된 데이터 다루기

- 누락된 값 → NaN, NULL로 대체
- 누락된 값을 다룰 수 없거나 무시 → 예상치 못한 결과 초래

## 1. 테이블 형태 데이터에서 누락된 값 식별

- 코드 작성

## 2. 누락된 값이 있는 훈련 샘플이나 특성 제외

- 데이터셋에서 해당 훈련 샘플이나 특성 완전히 삭제

## 3. 누락된 값 대체

- 데이터셋에 있는 다른 훈련 샘플로부터 누락된 값 추정
- 보간 기법 → 평균으로 대체
- 사이킷런 변환기 API → 데이터 변환에 관련된 파이썬 클래스 구현 가능
- 사이킷런 추정기 → predict 메서드, transform 메서드도 가능

# 2. 범주형 데이터 다루기

## 1. 판다스를 사용한 범주형 데이터 인코딩

- 코드 작성

## 2. 순서가 있는 특성 매핑

- 순서 특성 : 범주형의 문자열 값 → 정수 변환 필요

## 3. 클래스 레이블 인코딩

- 클래스 레이블 → 정수 배열로 전달

## 4. 순서가 없는 특성에 원-핫 인코딩 적용

- 원-핫 인코딩(One-Hot Encoding) : 순서 없는 특성에 들어 있는 고유한 값마다 새로운 더미 특성 생성
- 순서가 있는 특성 인코딩 → 임계 값을 사용하여 인코딩 가능

# 3. 데이터셋을 훈련 데이터셋과 테스트 데이터셋으로 나누기

- 코드 작성

# 4. 특성 스케일 맞추기

- 정규화(Normalization) : 특성의 스케일 → [0, 1] 범위에 맞추는 것
- 표준화(Standardization)
- 최소-최대 스케일 변환(Min-Max Scaling)

# 5. 유용한 특성 선택

- 일반화 오차 감소 방법
    - 더 많은 훈련 데이터 모음
    - 규제를 통해 복잡도 제한
    - 파라미터 개수가 적은 간단한 모델 선택
    - 데이터 차원 감소

## 1. 모델 복잡도 제한을 위한 L1 규제와 L2 규제

- L2 규제(L2 Regularization) : 개별 가중치 값을 제한하여 모델 복잡도 감소
- L1 규제(L1 Regularization) : 가중치 제곱 → 가중치 절댓값, 희소 특성 벡터 생성

## 2. L2 규제의 기하학적 해석

- 손실 함수에 페널티 항 추가
- 가중치 값 작게 만듦

## 3. L1 규제를 사용한 희소성

- 손실 함수 포물선, L1 다이아몬드 경계가 만나는 최적점 → 축에 가깝게 위치

## 4. 순차 특성 선택 알고리즘

- 차원 축소(Dimensionality Reduction)
    - 특성 선택(Feature Selection) : 원본 특성에서 일부 선택
    - 특성 추출(Feature Extraction) : 일련의 특성에서 얻은 정보로 새로운 특성 생성
- 순차 특성 선택(Sequential Feature Selection) : 탐욕적 탐색 알고리즘, 초기 차원의 특성 공간을 특정 부분 공간으로 축소
- 순차 후진 선택(SBS, Sequential Backward Selection) : 모델 성능을 가능한 적게 희생하면서 초기 특성의 부분 공간으로 차원 축소

# 6. 랜덤 포레스트의 특성 중요도 사용

- 앙상블에 참여한 모든 결정 트리에서 계산한 평균적인 불순도 감소로 특성 중요도 측정 가능