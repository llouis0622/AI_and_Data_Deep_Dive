# 1. 데이터셋

- WikiANN/PAN-X 교차 언어 전이 평가 벤치마크 데이터

# 2. 다중 언어 트랜스포머

- CoNLL-2002 데이터셋
- 영어, 네덜란드어, 스페인어, 독일어를 위한 벤치마트로 사용

# 3. XLM-R 토큰화

- SentencePiece 토크나이저 사용

## 1. 토큰화 파이프라인

- 정규화
    - 원시 문자를 더 깨끗하게 만들기 위해 적용되는 일련의 연산
    - 공백, 악센트 제거 등
    - 유니코드 정규화, 소문자 정규화 등
- 사전 토큰화(pretokenization)
    - 텍스트를 더 작은 객체로 분할 → 훈련 마지막에 생성되는 토큰의 상한선 제공
    - BPE, 유니그램 알고리즘 사용 → 부분단어로 분할
- 토크나이저 모델
    - 부분단어 분할 모델을 단어에 적용
    - 단어를 부분단어로 나눠 어휘사전 크기와 OOV 토큰 개수 감소
- 사후 처리
    - 토큰 리스트에 부가전인 변환 적용
    - 입력 토큰 인덱스의 시퀀스 처음과 끝 부분에 특수 토큰 추가 등

## 2. SentencePiece 토크나이저

- 유니그램 → 각 입력 텍스트를 유니코드 문자 시퀀스로 인코딩

# 4. 개체명 인식을  위한 트랜스포머

- BERT, 인코더 기반 트랜스포머 → 특수 토큰으로 전체 텍스트 시퀀스 표현
- RoBERTa 기반 → BERT의 모든 아키텍처 특징 보유

# 5. 트랜스포머 모델 클래스

- 기존 모델을 특정 작업에 맞춰 쉽게 확장 가능
- 특정 용도의 사용자 정의 모델 생성 가능

## 1. 바디와 헤드

- 헤드 : 모델의 마지막 층, 후속 작업에 맞는 층
- 바디 : 헤드를 제외한 나머지 부분

## 2. 토큰 분류를 위한 사용자 정의 모델 만들기

- 베이스 모델 선택 후 사용자 특화 설정 추가

## 3. 사용자 정의 모델 로드하기

- 모델 이름 + 몇 가지 정보 추가
- 각 개체명을 레이블링하는 데 사용할 태그, 각 태그를 ID로 매핑하는 딕셔너리, 반대의 딕셔너리 등

# 6. NER 작업을 위해 텍스트 토큰화하기

- 미세 튜닝 → 전체 데이터셋 토큰화
- 레이블 ID, 토큰 정렬

# 7. 성능 측정

- 정밀도, 재현율, F1 score 결과 보고

# 8. XLM-RoBERTa 미세 튜닝

- PAN-X 독일서 서브셋에 베이스 모델 미세 튜닝 → 프랑스어, 이탈리아어, 영어에서 제로샷 교차 언어 성능 평가

# 9. 오류 분석

- 너무 많은 토큰 마스킹, 일부 레이블도 마스킹 → 손실 감소
- 실제 성능 과대평가
- 클래스, 개체명이 일반 클래스처럼 포함됨

# 10. 교차 언어 전이

- 다른 언어로 전이 평가
- 제로샷 전이 사용 가능
- 다국어 동시에 미세 튜닝 가능

# 11. 모델 위젯 사용

- 파이프라인 → 허브 제공 위젯도 사용 가능