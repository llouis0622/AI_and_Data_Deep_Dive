# 1. CNN/DailyMail 데이터셋

- 30만 개의 뉴스 기사 + 요약 쌍
- 요약 → 본문에서 추출되지 않고 추상적임

# 2. 텍스트 요약 파이프라인

- 요약 문장 → 줄바꿈으로 나눔
- NLTK → 문장의 종결과 약어에 등장하는 구두점 구별

## 1. 요약 기준 모델

- 단순히 기사에서 맨 처음 문장 세 개 선택

## 2. GPT-2

- 입력 텍스트 뒤에 TL:DR 추가

## 3. T5

- 모든 작업을 텍스트-투-텍스트 작업으로 구성 → 범용 트랜스포머 아키텍처
- 미세 튜닝 없이 사용 가능

## 4. BART

- 인코더-디코더 구조 사용
- 손상된 입력 재구성

## 5. PEGASUS

- 인코더-디코더 트랜스포머
- 여러 문자으로 구성된 텍스트에서 마스킹된 문장 예측

# 3. 요약 결과 비교하기

- 정성적으로 합리적인 결과를 낸 모델 선택 가능
- 미세 튜닝을 통해 모델 튜닝

# 4. 생성된 텍스트 품질 평가하기

## 1. BLEU

- 생성된 텍스트에서 얼마나 많은 토큰이 참조 텍스트 토큰과 완벽하게 똑같이 정렬됐는지 확인하는 대신 단어, n-그램 체크
- 정밀도를 근간으로 하는 지표
- 두 텍스트 비교 시 참조 텍스트에 있는 단어가 생성된 텍스트에 얼마나 자주 등장하는지 카운트
- 브레비티 페널티(brevity penalty) : 최솟값 선택

## 2. ROUGE

- 높은 재현율이 정밀도보다 훨씬 더 중요한 요약 같은 애플리케이션을 위해 특별히 개발
- 참조 텍스트에 있는 n-그램이 생성된 텍스트에 얼마나 많이 등장하는지도 확인

# 5. CNN/DailyMail 데이터셋에서 PEGASUS 평가하기

- 테스트 세트 → 지표 → 요약 모델

# 6. 요약 모델 훈련하기

- SAMSum에서 PEGASUS 평가하기
- PEGASUS 미세 튜닝하기
- 대화 요약 생성하기