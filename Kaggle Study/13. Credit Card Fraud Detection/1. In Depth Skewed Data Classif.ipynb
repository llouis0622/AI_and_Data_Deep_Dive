{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-25T05:39:02.034518Z",
     "start_time": "2024-07-25T05:39:00.014830Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"../data/creditcard/creditcard.csv\")\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:39:12.164664Z",
     "start_time": "2024-07-25T05:39:12.050872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count_classes = pd.value_counts(data['Class'], sort=True).sort_index()\n",
    "count_classes.plot(kind='bar')\n",
    "plt.title(\"Fraud class histogram\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")"
   ],
   "id": "dbbd505ba0b477a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/9z2y6vy916ncn7tzc7rkg8140000gn/T/ipykernel_41172/2325710022.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  count_classes = pd.value_counts(data['Class'], sort=True).sort_index()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:39:58.875009Z",
     "start_time": "2024-07-25T05:39:58.799273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time', 'Amount'], axis=1)\n",
    "data.head()"
   ],
   "id": "4d9a4eb48ec3f345",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:41:14.655356Z",
     "start_time": "2024-07-25T05:41:14.630137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']"
   ],
   "id": "90be61ef6a9c9474",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:41:57.551202Z",
     "start_time": "2024-07-25T05:41:57.515644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_records_fraud = len(data[data.Class == 1])\n",
    "fraud_indices = np.array(data[data.Class == 1].index)\n",
    "normal_indices = data[data.Class == 0].index\n",
    "\n",
    "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace=False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "under_sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "under_sample_data = data.iloc[under_sample_indices, :]\n",
    "\n",
    "X_undersample = under_sample_data.iloc[:, under_sample_data.columns != 'Class']\n",
    "y_undersample = under_sample_data.iloc[:, under_sample_data.columns == 'Class']\n",
    "\n",
    "print(\"Percentage of normal transactions: \",\n",
    "      len(under_sample_data[under_sample_data.Class == 0]) / len(under_sample_data))\n",
    "print(\"Percentage of fraud transactions: \",\n",
    "      len(under_sample_data[under_sample_data.Class == 1]) / len(under_sample_data))\n",
    "print(\"Total number of transactions in resampled data: \", len(under_sample_data))"
   ],
   "id": "1c153d0c6f50ab55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of normal transactions:  0.5\n",
      "Percentage of fraud transactions:  0.5\n",
      "Total number of transactions in resampled data:  984\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:44:15.896278Z",
     "start_time": "2024-07-25T05:44:15.769522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Number transactions train dataset: \", len(X_train))\n",
    "print(\"Number transactions test dataset: \", len(X_test))\n",
    "print(\"Total number of transactions: \", len(X_train) + len(X_test))\n",
    "\n",
    "X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample\n",
    "                                                                                                    , y_undersample\n",
    "                                                                                                    , test_size=0.3\n",
    "                                                                                                    , random_state=0)\n",
    "print(\"\")\n",
    "print(\"Number transactions train dataset: \", len(X_train_undersample))\n",
    "print(\"Number transactions test dataset: \", len(X_test_undersample))\n",
    "print(\"Total number of transactions: \", len(X_train_undersample) + len(X_test_undersample))"
   ],
   "id": "baaa202a31ee88c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions train dataset:  199364\n",
      "Number transactions test dataset:  85443\n",
      "Total number of transactions:  284807\n",
      "\n",
      "Number transactions train dataset:  688\n",
      "Number transactions test dataset:  296\n",
      "Total number of transactions:  984\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:46:08.938496Z",
     "start_time": "2024-07-25T05:46:08.931216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def printing_Kfold_scores(x_train_data, y_train_data):\n",
    "    fold = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "\n",
    "    c_param_range = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "    results_table = pd.DataFrame(index=range(len(c_param_range)), columns=['C_parameter', 'Mean recall score'])\n",
    "    results_table['C_parameter'] = c_param_range\n",
    "\n",
    "    j = 0\n",
    "    for c_param in c_param_range:\n",
    "        print('-------------------------------------------')\n",
    "        print('C parameter: ', c_param)\n",
    "        print('-------------------------------------------')\n",
    "        print('')\n",
    "\n",
    "        recall_accs = []\n",
    "        for iteration, (train_index, test_index) in enumerate(fold.split(x_train_data), start=1):\n",
    "            lr = LogisticRegression(C=c_param, penalty='l1', solver='liblinear')\n",
    "            lr.fit(x_train_data.iloc[train_index, :], y_train_data.iloc[train_index].values.ravel())\n",
    "\n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[test_index, :].values)\n",
    "\n",
    "            recall_acc = recall_score(y_train_data.iloc[test_index].values, y_pred_undersample)\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration ', iteration, ': recall score = ', recall_acc)\n",
    "\n",
    "        results_table.loc[j, 'Mean recall score'] = np.mean(recall_accs)\n",
    "        j += 1\n",
    "        print('')\n",
    "        print('Mean recall score ', np.mean(recall_accs))\n",
    "        print('')\n",
    "\n",
    "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n",
    "\n",
    "    print('*********************************************************************************')\n",
    "    print('Best model to choose from cross validation is with C parameter = ', best_c)\n",
    "    print('*********************************************************************************')\n",
    "\n",
    "    return best_c"
   ],
   "id": "8c19df4219e99019",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:46:18.120352Z",
     "start_time": "2024-07-25T05:46:17.757732Z"
    }
   },
   "cell_type": "code",
   "source": "best_c = printing_Kfold_scores(X_train_undersample, y_train_undersample)",
   "id": "15733c642e73522d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "C parameter:  0.01\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.958904109589041\n",
      "Iteration  2 : recall score =  0.9178082191780822\n",
      "Iteration  3 : recall score =  1.0\n",
      "Iteration  4 : recall score =  0.9594594594594594\n",
      "Iteration  5 : recall score =  0.9545454545454546\n",
      "\n",
      "Mean recall score  0.9581434485544076\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  0.1\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.8493150684931506\n",
      "Iteration  2 : recall score =  0.863013698630137\n",
      "Iteration  3 : recall score =  0.9322033898305084\n",
      "Iteration  4 : recall score =  0.9324324324324325\n",
      "Iteration  5 : recall score =  0.9090909090909091\n",
      "\n",
      "Mean recall score  0.8972110996954274\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  1\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.8493150684931506\n",
      "Iteration  2 : recall score =  0.8767123287671232\n",
      "Iteration  3 : recall score =  0.9830508474576272\n",
      "Iteration  4 : recall score =  0.9459459459459459\n",
      "Iteration  5 : recall score =  0.9090909090909091\n",
      "\n",
      "Mean recall score  0.9128230199509512\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  10\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.863013698630137\n",
      "Iteration  2 : recall score =  0.863013698630137\n",
      "Iteration  3 : recall score =  0.9830508474576272\n",
      "Iteration  4 : recall score =  0.9324324324324325\n",
      "Iteration  5 : recall score =  0.9090909090909091\n",
      "\n",
      "Mean recall score  0.9101203172482485\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  100\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.863013698630137\n",
      "Iteration  2 : recall score =  0.863013698630137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  3 : recall score =  0.9830508474576272\n",
      "Iteration  4 : recall score =  0.9459459459459459\n",
      "Iteration  5 : recall score =  0.9090909090909091\n",
      "\n",
      "Mean recall score  0.9128230199509512\n",
      "\n",
      "*********************************************************************************\n",
      "Best model to choose from cross validation is with C parameter =  0.01\n",
      "*********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:46:49.823812Z",
     "start_time": "2024-07-25T05:46:49.816587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    else:\n",
    "        1\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ],
   "id": "706acc4715905823",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:48:35.668758Z",
     "start_time": "2024-07-25T05:48:35.638335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(C=best_c, penalty='l1', solver='liblinear')\n",
    "lr.fit(X_train_undersample, y_train_undersample.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test_undersample.values)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test_undersample, y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1, 1] / (cnf_matrix[1, 0] + cnf_matrix[1, 1]))\n",
    "\n",
    "class_names = [0, 1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ],
   "id": "faa9bf113aadf914",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m lr\u001B[38;5;241m.\u001B[39mfit(X_train_undersample, y_train_undersample\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mravel())\n\u001B[1;32m      3\u001B[0m y_pred_undersample \u001B[38;5;241m=\u001B[39m lr\u001B[38;5;241m.\u001B[39mpredict(X_test_undersample\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[0;32m----> 5\u001B[0m cnf_matrix \u001B[38;5;241m=\u001B[39m confusion_matrix(y_test_undersample, y_pred_undersample)\n\u001B[1;32m      6\u001B[0m np\u001B[38;5;241m.\u001B[39mset_printoptions(precision\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecall metric in the testing dataset: \u001B[39m\u001B[38;5;124m\"\u001B[39m, cnf_matrix[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m/\u001B[39m (cnf_matrix[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m cnf_matrix[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m]))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:48:57.241205Z",
     "start_time": "2024-07-25T05:48:57.204252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(C=best_c, penalty='l1')\n",
    "lr.fit(X_train_undersample, y_train_undersample.values.ravel())\n",
    "y_pred = lr.predict(X_test.values)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1, 1] / (cnf_matrix[1, 0] + cnf_matrix[1, 1]))\n",
    "\n",
    "class_names = [0, 1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ],
   "id": "bc9f22ab02f6ddd6",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m lr \u001B[38;5;241m=\u001B[39m LogisticRegression(C\u001B[38;5;241m=\u001B[39mbest_c, penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m lr\u001B[38;5;241m.\u001B[39mfit(X_train_undersample, y_train_undersample\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mravel())\n\u001B[1;32m      3\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m lr\u001B[38;5;241m.\u001B[39mpredict(X_test\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m      5\u001B[0m cnf_matrix \u001B[38;5;241m=\u001B[39m confusion_matrix(y_test, y_pred)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1194\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1165\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;124;03m    Fit the model according to the given training data.\u001B[39;00m\n\u001B[1;32m   1168\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001B[39;00m\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1194\u001B[0m     solver \u001B[38;5;241m=\u001B[39m _check_solver(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdual)\n\u001B[1;32m   1196\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml1_ratio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1197\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1198\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml1_ratio parameter is only used when penalty is \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1199\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1200\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(penalty=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty)\n\u001B[1;32m   1201\u001B[0m         )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:67\u001B[0m, in \u001B[0;36m_check_solver\u001B[0;34m(solver, penalty, dual)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_solver\u001B[39m(solver, penalty, dual):\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solver \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m penalty \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 67\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     68\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolver \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m supports only \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or None penalties, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpenalty\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     69\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpenalty.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     70\u001B[0m         )\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solver \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m dual:\n\u001B[1;32m     72\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolver \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m supports only dual=False, got dual=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdual\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty."
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:49:11.204331Z",
     "start_time": "2024-07-25T05:49:11.145768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(C=best_c, penalty='l1')\n",
    "y_pred_undersample_score = lr.fit(X_train_undersample, y_train_undersample.values.ravel()).decision_function(\n",
    "    X_test_undersample.values)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_undersample.values.ravel(), y_pred_undersample_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.1, 1.0])\n",
    "plt.ylim([-0.1, 1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ],
   "id": "4eb68f93dd4cd418",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m lr \u001B[38;5;241m=\u001B[39m LogisticRegression(C\u001B[38;5;241m=\u001B[39mbest_c, penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m y_pred_undersample_score \u001B[38;5;241m=\u001B[39m lr\u001B[38;5;241m.\u001B[39mfit(X_train_undersample, y_train_undersample\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mravel())\u001B[38;5;241m.\u001B[39mdecision_function(\n\u001B[1;32m      3\u001B[0m     X_test_undersample\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m      5\u001B[0m fpr, tpr, thresholds \u001B[38;5;241m=\u001B[39m roc_curve(y_test_undersample\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mravel(), y_pred_undersample_score)\n\u001B[1;32m      6\u001B[0m roc_auc \u001B[38;5;241m=\u001B[39m auc(fpr, tpr)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1194\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1165\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;124;03m    Fit the model according to the given training data.\u001B[39;00m\n\u001B[1;32m   1168\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001B[39;00m\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1194\u001B[0m     solver \u001B[38;5;241m=\u001B[39m _check_solver(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdual)\n\u001B[1;32m   1196\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml1_ratio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1197\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1198\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml1_ratio parameter is only used when penalty is \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1199\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1200\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(penalty=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty)\n\u001B[1;32m   1201\u001B[0m         )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:67\u001B[0m, in \u001B[0;36m_check_solver\u001B[0;34m(solver, penalty, dual)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_solver\u001B[39m(solver, penalty, dual):\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solver \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m penalty \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 67\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     68\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolver \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m supports only \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or None penalties, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpenalty\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     69\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpenalty.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     70\u001B[0m         )\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solver \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m dual:\n\u001B[1;32m     72\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolver \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m supports only dual=False, got dual=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdual\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty."
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:50:19.298101Z",
     "start_time": "2024-07-25T05:49:19.175196Z"
    }
   },
   "cell_type": "code",
   "source": "best_c = printing_Kfold_scores(X_train, y_train)",
   "id": "8b19c2f0e80176ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "C parameter:  0.01\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1 : recall score =  0.4925373134328358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2 : recall score =  0.6027397260273972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  3 : recall score =  0.6833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  4 : recall score =  0.5692307692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  5 : recall score =  0.45\n",
      "\n",
      "Mean recall score  0.5595682284048672\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  0.1\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1 : recall score =  0.5671641791044776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2 : recall score =  0.6164383561643836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  3 : recall score =  0.6833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  4 : recall score =  0.5846153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  5 : recall score =  0.525\n",
      "\n",
      "Mean recall score  0.5953102506435158\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  1\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1 : recall score =  0.5522388059701493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2 : recall score =  0.6164383561643836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  3 : recall score =  0.7166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  4 : recall score =  0.6153846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  5 : recall score =  0.5625\n",
      "\n",
      "Mean recall score  0.612645688837163\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  10\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1 : recall score =  0.5522388059701493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2 : recall score =  0.6164383561643836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  3 : recall score =  0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  4 : recall score =  0.6153846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  5 : recall score =  0.575\n",
      "\n",
      "Mean recall score  0.6184790221704963\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  100\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1 : recall score =  0.5522388059701493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2 : recall score =  0.6164383561643836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  3 : recall score =  0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  4 : recall score =  0.6153846153846154\n",
      "Iteration  5 : recall score =  0.575\n",
      "\n",
      "Mean recall score  0.6184790221704963\n",
      "\n",
      "*********************************************************************************\n",
      "Best model to choose from cross validation is with C parameter =  10.0\n",
      "*********************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:50:28.191866Z",
     "start_time": "2024-07-25T05:50:28.142959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(C=best_c, penalty='l1')\n",
    "lr.fit(X_train, y_train.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test.values)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1, 1] / (cnf_matrix[1, 0] + cnf_matrix[1, 1]))\n",
    "\n",
    "class_names = [0, 1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix')\n",
    "plt.show()"
   ],
   "id": "32e73fe1bdb2c2f6",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m lr \u001B[38;5;241m=\u001B[39m LogisticRegression(C\u001B[38;5;241m=\u001B[39mbest_c, penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m lr\u001B[38;5;241m.\u001B[39mfit(X_train, y_train\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mravel())\n\u001B[1;32m      3\u001B[0m y_pred_undersample \u001B[38;5;241m=\u001B[39m lr\u001B[38;5;241m.\u001B[39mpredict(X_test\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m      5\u001B[0m cnf_matrix \u001B[38;5;241m=\u001B[39m confusion_matrix(y_test, y_pred_undersample)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1194\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1165\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;124;03m    Fit the model according to the given training data.\u001B[39;00m\n\u001B[1;32m   1168\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001B[39;00m\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1194\u001B[0m     solver \u001B[38;5;241m=\u001B[39m _check_solver(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdual)\n\u001B[1;32m   1196\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml1_ratio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1197\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1198\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml1_ratio parameter is only used when penalty is \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1199\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1200\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(penalty=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty)\n\u001B[1;32m   1201\u001B[0m         )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:67\u001B[0m, in \u001B[0;36m_check_solver\u001B[0;34m(solver, penalty, dual)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_solver\u001B[39m(solver, penalty, dual):\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solver \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m penalty \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 67\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     68\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolver \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m supports only \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or None penalties, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpenalty\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     69\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpenalty.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     70\u001B[0m         )\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solver \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m dual:\n\u001B[1;32m     72\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolver \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m supports only dual=False, got dual=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdual\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty."
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:50:52.996262Z",
     "start_time": "2024-07-25T05:50:52.948787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = LogisticRegression(C=0.01, penalty='l1')\n",
    "lr.fit(X_train_undersample, y_train_undersample.values.ravel())\n",
    "y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values)\n",
    "\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "j = 1\n",
    "for i in thresholds:\n",
    "    y_test_predictions_high_recall = y_pred_undersample_proba[:, 1] > i\n",
    "\n",
    "    plt.subplot(3, 3, j)\n",
    "    j += 1\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_test_undersample, y_test_predictions_high_recall)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    print(\"Recall metric in the testing dataset: \", cnf_matrix[1, 1] / (cnf_matrix[1, 0] + cnf_matrix[1, 1]))\n",
    "\n",
    "    class_names = [0, 1]\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, title='Threshold >= %s' % i)"
   ],
   "id": "ec7173b1d15e8dad",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m lr \u001B[38;5;241m=\u001B[39m LogisticRegression(C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m lr\u001B[38;5;241m.\u001B[39mfit(X_train_undersample, y_train_undersample\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mravel())\n\u001B[1;32m      3\u001B[0m y_pred_undersample_proba \u001B[38;5;241m=\u001B[39m lr\u001B[38;5;241m.\u001B[39mpredict_proba(X_test_undersample\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m      5\u001B[0m thresholds \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.2\u001B[39m, \u001B[38;5;241m0.3\u001B[39m, \u001B[38;5;241m0.4\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.6\u001B[39m, \u001B[38;5;241m0.7\u001B[39m, \u001B[38;5;241m0.8\u001B[39m, \u001B[38;5;241m0.9\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1194\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1165\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;124;03m    Fit the model according to the given training data.\u001B[39;00m\n\u001B[1;32m   1168\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001B[39;00m\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1194\u001B[0m     solver \u001B[38;5;241m=\u001B[39m _check_solver(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdual)\n\u001B[1;32m   1196\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml1_ratio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1197\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1198\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml1_ratio parameter is only used when penalty is \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1199\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1200\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(penalty=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty)\n\u001B[1;32m   1201\u001B[0m         )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:67\u001B[0m, in \u001B[0;36m_check_solver\u001B[0;34m(solver, penalty, dual)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_solver\u001B[39m(solver, penalty, dual):\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solver \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m penalty \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 67\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     68\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolver \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m supports only \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or None penalties, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpenalty\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     69\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpenalty.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     70\u001B[0m         )\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solver \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m dual:\n\u001B[1;32m     72\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolver \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m supports only dual=False, got dual=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdual\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty."
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:51:12.568071Z",
     "start_time": "2024-07-25T05:51:12.514718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import cycle\n",
    "\n",
    "lr = LogisticRegression(C=0.01, penalty='l1')\n",
    "lr.fit(X_train_undersample, y_train_undersample.values.ravel())\n",
    "y_pred_undersample_proba = lr.predict_proba(X_test_undersample.values)\n",
    "\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal', 'red', 'yellow', 'green', 'blue', 'black'])\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "j = 1\n",
    "for i, color in zip(thresholds, colors):\n",
    "    y_test_predictions_prob = y_pred_undersample_proba[:, 1] > i\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test_undersample, y_test_predictions_prob)\n",
    "\n",
    "    plt.plot(recall, precision, color=color, label='Threshold: %s' % i)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall example')\n",
    "    plt.legend(loc=\"lower left\")"
   ],
   "id": "e0bd8672a47dc82a",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cycle\n\u001B[1;32m      3\u001B[0m lr \u001B[38;5;241m=\u001B[39m LogisticRegression(C\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m lr\u001B[38;5;241m.\u001B[39mfit(X_train_undersample, y_train_undersample\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mravel())\n\u001B[1;32m      5\u001B[0m y_pred_undersample_proba \u001B[38;5;241m=\u001B[39m lr\u001B[38;5;241m.\u001B[39mpredict_proba(X_test_undersample\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m      7\u001B[0m thresholds \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.2\u001B[39m, \u001B[38;5;241m0.3\u001B[39m, \u001B[38;5;241m0.4\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.6\u001B[39m, \u001B[38;5;241m0.7\u001B[39m, \u001B[38;5;241m0.8\u001B[39m, \u001B[38;5;241m0.9\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1194\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1165\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   1166\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;124;03m    Fit the model according to the given training data.\u001B[39;00m\n\u001B[1;32m   1168\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;124;03m    The SAGA solver supports both float64 and float32 bit arrays.\u001B[39;00m\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1194\u001B[0m     solver \u001B[38;5;241m=\u001B[39m _check_solver(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdual)\n\u001B[1;32m   1196\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml1_ratio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1197\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1198\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml1_ratio parameter is only used when penalty is \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1199\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1200\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(penalty=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty)\n\u001B[1;32m   1201\u001B[0m         )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:67\u001B[0m, in \u001B[0;36m_check_solver\u001B[0;34m(solver, penalty, dual)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_solver\u001B[39m(solver, penalty, dual):\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solver \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m penalty \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 67\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     68\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolver \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m supports only \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml2\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or None penalties, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpenalty\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     69\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpenalty.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     70\u001B[0m         )\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solver \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m dual:\n\u001B[1;32m     72\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSolver \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msolver\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m supports only dual=False, got dual=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdual\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty."
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
