{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-10T06:27:29.430756Z",
     "start_time": "2024-07-10T06:27:28.653826Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from matplotlib import rc\n",
    "\n",
    "rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:27:56.772401Z",
     "start_time": "2024-07-10T06:27:56.768056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def encode_data(df):\n",
    "    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])\n",
    "\n",
    "\n",
    "def feature_importance(forest, X_train, display_results=True):\n",
    "    ranked_list = []\n",
    "    zero_features = []\n",
    "\n",
    "    importances = forest.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    if display_results:\n",
    "        print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X_train.shape[1]):\n",
    "        if display_results:\n",
    "            print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]) + \" - \" + X_train.columns[\n",
    "                indices[f]])\n",
    "\n",
    "        ranked_list.append(X_train.columns[indices[f]])\n",
    "\n",
    "        if importances[indices[f]] == 0.0:\n",
    "            zero_features.append(X_train.columns[indices[f]])\n",
    "\n",
    "    return ranked_list, zero_features"
   ],
   "id": "95e44f426801b293",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:28:42.962352Z",
     "start_time": "2024-07-10T06:28:42.955488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def do_features(df):\n",
    "    feats_div = [('children_fraction', 'r4t1', 'r4t3'),\n",
    "                 ('working_man_fraction', 'r4h2', 'r4t3'),\n",
    "                 ('all_man_fraction', 'r4h3', 'r4t3'),\n",
    "                 ('human_density', 'tamviv', 'rooms'),\n",
    "                 ('human_bed_density', 'tamviv', 'bedrooms'),\n",
    "                 ('rent_per_person', 'v2a1', 'r4t3'),\n",
    "                 ('rent_per_room', 'v2a1', 'rooms'),\n",
    "                 ('mobile_density', 'qmobilephone', 'r4t3'),\n",
    "                 ('tablet_density', 'v18q1', 'r4t3'),\n",
    "                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n",
    "                 ('tablet_adult_density', 'v18q1', 'r4t2'),\n",
    "                 ]\n",
    "\n",
    "    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n",
    "                 ('people_weird_stat', 'tamhog', 'r4t3')]\n",
    "\n",
    "    for f_new, f1, f2 in feats_div:\n",
    "        df['fe_' + f_new] = (df[f1] / df[f2]).astype(np.float32)\n",
    "    for f_new, f1, f2 in feats_sub:\n",
    "        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n",
    "\n",
    "    aggs_num = {'age': ['min', 'max', 'mean'], 'escolari': ['min', 'max', 'mean']}\n",
    "\n",
    "    aggs_cat = {'dis': ['mean']}\n",
    "    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n",
    "        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n",
    "            aggs_cat[f_] = ['mean', 'count']\n",
    "\n",
    "    for name_, df_ in [('18', df.query('age >= 18'))]:\n",
    "        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n",
    "        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "        df = df.join(df_agg, how='left', on='idhogar')\n",
    "        del df_agg\n",
    "\n",
    "    df.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ],
   "id": "4366f8c189914a8f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:29:30.769550Z",
     "start_time": "2024-07-10T06:29:30.764803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_OHE2LE(df):\n",
    "    tmp_df = df.copy(deep=True)\n",
    "    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar', 'elimbasu',\n",
    "               'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco',\n",
    "               'instlevel', 'lugar', 'tipovivi',\n",
    "               'manual_elec']:\n",
    "        if 'manual_' not in s_:\n",
    "            cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n",
    "        elif 'elec' in s_:\n",
    "            cols_s_ = ['public', 'planpri', 'noelec', 'coopele']\n",
    "\n",
    "        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "\n",
    "        if 0 in sum_ohe:\n",
    "            print('The OHE in {} is incomplete. A new column will be added before label encoding'.format(s_))\n",
    "            col_dummy = s_ + '_dummy'\n",
    "            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n",
    "            cols_s_.append(col_dummy)\n",
    "            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "            if 0 in sum_ohe:\n",
    "                print(\"The category completion did not work\")\n",
    "        tmp_cat = tmp_df[cols_s_].idxmax(axis=1)\n",
    "        tmp_df[s_ + '_LE'] = LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n",
    "        if 'parentesco1' in cols_s_:\n",
    "            cols_s_.remove('parentesco1')\n",
    "        tmp_df.drop(cols_s_, axis=1, inplace=True)\n",
    "    return tmp_df"
   ],
   "id": "79590135a0acc73d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:29:50.793015Z",
     "start_time": "2024-07-10T06:29:50.592602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('../data/household/train.csv')\n",
    "test = pd.read_csv('../data/household/test.csv')\n",
    "\n",
    "test_ids = test.Id"
   ],
   "id": "6e39db9cc901e139",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:30:01.924571Z",
     "start_time": "2024-07-10T06:30:01.779064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_df(df_):\n",
    "    encode_data(df_)\n",
    "    return do_features(df_)\n",
    "\n",
    "\n",
    "train = process_df(train)\n",
    "test = process_df(test)"
   ],
   "id": "d57c888f58e38610",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:30:42.358642Z",
     "start_time": "2024-07-10T06:30:42.320096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train['dependency'] = np.sqrt(train['SQBdependency'])\n",
    "test['dependency'] = np.sqrt(test['SQBdependency'])\n",
    "\n",
    "train.loc[train['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "train.loc[train['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "test.loc[test['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "test.loc[test['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "\n",
    "train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"edjefa\"] = train.loc[\n",
    "    (train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"edjefe\"] = train.loc[\n",
    "    (train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"edjefa\"] = test.loc[\n",
    "    (test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"edjefe\"] = test.loc[\n",
    "    (test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "train.loc[train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "train.loc[train['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "test.loc[test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "test.loc[test['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "train['edjefe'] = train['edjefe'].astype(\"int\")\n",
    "train['edjefa'] = train['edjefa'].astype(\"int\")\n",
    "test['edjefe'] = test['edjefe'].astype(\"int\")\n",
    "test['edjefa'] = test['edjefa'].astype(\"int\")\n",
    "\n",
    "train['edjef'] = np.max(train[['edjefa', 'edjefe']], axis=1)\n",
    "test['edjef'] = np.max(test[['edjefa', 'edjefe']], axis=1)\n",
    "\n",
    "train['v2a1'] = train['v2a1'].fillna(0)\n",
    "test['v2a1'] = test['v2a1'].fillna(0)\n",
    "\n",
    "test['v18q1'] = test['v18q1'].fillna(0)\n",
    "train['v18q1'] = train['v18q1'].fillna(0)\n",
    "\n",
    "train['rez_esc'] = train['rez_esc'].fillna(0)\n",
    "test['rez_esc'] = test['rez_esc'].fillna(0)\n",
    "\n",
    "train.loc[train.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "train.loc[train.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "test.loc[test.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "test.loc[test.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "train.loc[(train.v14a == 1) & (train.sanitario1 == 1) & (train.abastaguano == 0), \"v14a\"] = 0\n",
    "train.loc[(train.v14a == 1) & (train.sanitario1 == 1) & (train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "test.loc[(test.v14a == 1) & (test.sanitario1 == 1) & (test.abastaguano == 0), \"v14a\"] = 0\n",
    "test.loc[(test.v14a == 1) & (test.sanitario1 == 1) & (test.abastaguano == 0), \"sanitario1\"] = 0"
   ],
   "id": "dc49bf4110205576",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:30:50.458197Z",
     "start_time": "2024-07-10T06:30:50.454849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_test_apply_func(train_, test_, func_):\n",
    "    test_['Target'] = 0\n",
    "    xx = pd.concat([train_, test_])\n",
    "\n",
    "    xx_func = func_(xx)\n",
    "    train_ = xx_func.iloc[:train_.shape[0], :]\n",
    "    test_ = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n",
    "\n",
    "    del xx, xx_func\n",
    "    return train_, test_"
   ],
   "id": "6c1961993013d9f5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:30:56.488421Z",
     "start_time": "2024-07-10T06:30:56.210512Z"
    }
   },
   "cell_type": "code",
   "source": "train, test = train_test_apply_func(train, test, convert_OHE2LE)",
   "id": "ee8d222050e37c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OHE in techo is incomplete. A new column will be added before label encoding\n",
      "The OHE in instlevel is incomplete. A new column will be added before label encoding\n",
      "The OHE in manual_elec is incomplete. A new column will be added before label encoding\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:31:18.684319Z",
     "start_time": "2024-07-10T06:31:18.632172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE',\n",
    "              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE',\n",
    "              'pared_LE']\n",
    "cols_nums = ['age', 'meaneduc', 'dependency',\n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']\n",
    "\n",
    "\n",
    "def convert_geo2aggs(df_):\n",
    "    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar'] + cols_nums)],\n",
    "                        pd.get_dummies(df_[cols_2_ohe], columns=cols_2_ohe)], axis=1)\n",
    "\n",
    "    geo_agg = tmp_df.groupby(['lugar_LE', 'idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)\n",
    "    geo_agg.columns = pd.Index(['geo_' + e for e in geo_agg.columns.tolist()])\n",
    "\n",
    "    del tmp_df\n",
    "    return df_.join(geo_agg, how='left', on='lugar_LE')\n",
    "\n",
    "\n",
    "train, test = train_test_apply_func(train, test, convert_geo2aggs)"
   ],
   "id": "eeea91c7eb41e14c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:33:00.707608Z",
     "start_time": "2024-07-10T06:33:00.645403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train['num_over_18'] = train[train.age >= 18].groupby('idhogar')['age'].transform(\"count\")\n",
    "train['num_over_18'] = train.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "train['num_over_18'] = train['num_over_18'].fillna(0).astype(int)\n",
    "\n",
    "test['num_over_18'] = test[test.age >= 18].groupby('idhogar')['age'].transform(\"count\")\n",
    "test['num_over_18'] = test.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "test['num_over_18'] = test['num_over_18'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "def extract_features(df):\n",
    "    df['bedrooms_to_rooms'] = df['bedrooms'] / df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1'] / df['rooms']\n",
    "    df['tamhog_to_rooms'] = df['tamhog'] / df['rooms']\n",
    "    df['r4t3_to_tamhog'] = df['r4t3'] / df['tamhog']\n",
    "    df['r4t3_to_rooms'] = df['r4t3'] / df['rooms']\n",
    "    df['v2a1_to_r4t3'] = df['v2a1'] / df['r4t3']\n",
    "    df['v2a1_to_r4t3'] = df['v2a1'] / (df['r4t3'] - df['r4t1'])\n",
    "    df['hhsize_to_rooms'] = df['hhsize'] / df['rooms']\n",
    "    df['rent_to_hhsize'] = df['v2a1'] / df['hhsize']\n",
    "    df['rent_to_over_18'] = df['v2a1'] / df['num_over_18']\n",
    "    df.loc[df.num_over_18 == 0, \"rent_to_over_18\"] = np.nan\n",
    "\n",
    "\n",
    "extract_features(train)\n",
    "extract_features(test)\n",
    "\n",
    "train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "train.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ],
   "id": "dea0f3a96c229d26",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:33:14.025447Z",
     "start_time": "2024-07-10T06:33:14.017949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "needless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq', 'mobilephone', 'female', ]\n",
    "\n",
    "instlevel_cols = [s for s in train.columns.tolist() if 'instlevel' in s]\n",
    "\n",
    "needless_cols.extend(instlevel_cols)\n",
    "\n",
    "train = train.drop(needless_cols, axis=1)\n",
    "test = test.drop(needless_cols, axis=1)"
   ],
   "id": "deb579bf516a760e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:33:39.947153Z",
     "start_time": "2024-07-10T06:33:39.943767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_data(train, y, sample_weight=None, households=None, test_percentage=0.20, seed=None):\n",
    "    train2 = train.copy()\n",
    "\n",
    "    cv_hhs = np.random.choice(households, size=int(len(households) * test_percentage), replace=False)\n",
    "    cv_idx = np.isin(households, cv_hhs)\n",
    "    X_test = train2[cv_idx]\n",
    "    y_test = y[cv_idx]\n",
    "\n",
    "    X_train = train2[~cv_idx]\n",
    "    y_train = y[~cv_idx]\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        y_train_weights = sample_weight[~cv_idx]\n",
    "        return X_train, y_train, X_test, y_test, y_train_weights\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ],
   "id": "b8b3864f04cba18d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:33:56.805617Z",
     "start_time": "2024-07-10T06:33:56.787246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = train.query('parentesco1==1')\n",
    "\n",
    "y = X['Target'] - 1\n",
    "X = X.drop(['Target'], axis=1)\n",
    "\n",
    "np.random.seed(seed=None)\n",
    "\n",
    "train2 = X.copy()\n",
    "\n",
    "train_hhs = train2.idhogar\n",
    "\n",
    "households = train2.idhogar.unique()\n",
    "cv_hhs = np.random.choice(households, size=int(len(households) * 0.15), replace=False)\n",
    "\n",
    "cv_idx = np.isin(train2.idhogar, cv_hhs)\n",
    "\n",
    "X_test = train2[cv_idx]\n",
    "y_test = y[cv_idx]\n",
    "\n",
    "X_train = train2[~cv_idx]\n",
    "y_train = y[~cv_idx]\n",
    "\n",
    "X_train = train2\n",
    "y_train = y\n",
    "\n",
    "train_households = X_train.idhogar"
   ],
   "id": "36820ee72efcaaf2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:34:05.398911Z",
     "start_time": "2024-07-10T06:34:05.395675Z"
    }
   },
   "cell_type": "code",
   "source": "y_train_weights = class_weight.compute_sample_weight('balanced', y_train, indices=None)",
   "id": "c99ba3ab7a7f3040",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:34:20.912213Z",
     "start_time": "2024-07-10T06:34:20.909590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extra_drop_features = [\n",
    "    'agg18_estadocivil1_MEAN',\n",
    "    'agg18_estadocivil6_COUNT',\n",
    "    'agg18_estadocivil7_COUNT',\n",
    "    'agg18_parentesco10_COUNT',\n",
    "    'agg18_parentesco11_COUNT',\n",
    "    'agg18_parentesco12_COUNT',\n",
    "    'agg18_parentesco1_COUNT',\n",
    "    'agg18_parentesco2_COUNT',\n",
    "    'agg18_parentesco3_COUNT',\n",
    "    'agg18_parentesco4_COUNT',\n",
    "    'agg18_parentesco5_COUNT',\n",
    "    'agg18_parentesco6_COUNT',\n",
    "    'agg18_parentesco7_COUNT',\n",
    "    'agg18_parentesco8_COUNT',\n",
    "    'agg18_parentesco9_COUNT',\n",
    "    'geo_elimbasu_LE_4',\n",
    "    'geo_energcocinar_LE_1',\n",
    "    'geo_energcocinar_LE_2',\n",
    "    'geo_epared_LE_0',\n",
    "    'geo_hogar_mayor',\n",
    "    'geo_manual_elec_LE_2',\n",
    "    'geo_pared_LE_3',\n",
    "    'geo_pared_LE_4',\n",
    "    'geo_pared_LE_5',\n",
    "    'geo_pared_LE_6',\n",
    "    'num_over_18',\n",
    "    'parentesco_LE',\n",
    "    'rez_esc']"
   ],
   "id": "f8eb6cd41ffcae3b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:34:27.738833Z",
     "start_time": "2024-07-10T06:34:27.736872Z"
    }
   },
   "cell_type": "code",
   "source": "xgb_drop_cols = extra_drop_features + [\"idhogar\", 'parentesco1']",
   "id": "2f26f8b2a307dc20",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:35:04.477911Z",
     "start_time": "2024-07-10T06:35:04.473628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opt_parameters = {'max_depth': 35, 'eta': 0.1, 'silent': 0, 'objective': 'multi:softmax', 'min_child_weight': 1,\n",
    "                  'num_class': 4, 'gamma': 2.0, 'colsample_bylevel': 0.9, 'subsample': 0.84, 'colsample_bytree': 0.88,\n",
    "                  'reg_lambda': 0.40}\n",
    "\n",
    "opt_parameters = {'max_depth': 35, 'eta': 0.15, 'silent': 1, 'objective': 'multi:softmax', 'min_child_weight': 2,\n",
    "                  'num_class': 4, 'gamma': 2.5, 'colsample_bylevel': 1, 'subsample': 0.95, 'colsample_bytree': 0.85,\n",
    "                  'reg_lambda': 0.35}\n",
    "\n",
    "\n",
    "def evaluate_macroF1_lgb(predictions, truth):\n",
    "    pred_labels = predictions.argmax(axis=1)\n",
    "    truth = truth.get_label()\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', 1 - f1)\n",
    "\n",
    "\n",
    "fit_params = {\"early_stopping_rounds\": 500,\n",
    "              \"eval_metric\": evaluate_macroF1_lgb,\n",
    "              \"eval_set\": [(X_train, y_train), (X_test, y_test)],\n",
    "              'verbose': False,\n",
    "              }\n",
    "\n",
    "\n",
    "def learning_rate_power_0997(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    min_learning_rate = 0.02\n",
    "    lr = base_learning_rate * np.power(.995, current_iter)\n",
    "    return max(lr, min_learning_rate)\n",
    "\n",
    "\n",
    "fit_params['verbose'] = 50"
   ],
   "id": "661a0bc83a673f5d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:36:38.609278Z",
     "start_time": "2024-07-10T06:36:38.597268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "\n",
    "def _parallel_fit_estimator(estimator1, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "    estimator = clone(estimator1)\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        X_train, y_train, X_test, y_test, y_train_weight = split_data(X, y, sample_weight, households=train_households)\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = split_data(X, y, None, households=train_households)\n",
    "\n",
    "    fit_params[\"eval_set\"] = [(X_test, y_test)]\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(X_train, y_train, sample_weight=y_train_weight, **fit_params)\n",
    "    else:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "    if not isinstance(estimator1, ExtraTreesClassifier) and not isinstance(estimator1,\n",
    "                                                                           RandomForestClassifier) and not isinstance(\n",
    "        estimator1, xgb.XGBClassifier):\n",
    "        best_cv_round = np.argmax(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_cv = np.max(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_train = estimator.evals_result_['train']['macroF1'][best_cv_round]\n",
    "    else:\n",
    "        best_train = f1_score(y_train, estimator.predict(X_train), average=\"macro\")\n",
    "        best_cv = f1_score(y_test, estimator.predict(X_test), average=\"macro\")\n",
    "        print(\"Train F1:\", best_train)\n",
    "        print(\"Test F1:\", best_cv)\n",
    "\n",
    "    if threshold:\n",
    "        if ((best_cv > 0.37) and (best_train > 0.75)) or ((best_cv > 0.44) and (best_train > 0.65)):\n",
    "            return estimator\n",
    "        else:\n",
    "            print(\"Unacceptable!!! Trying again...\")\n",
    "            return _parallel_fit_estimator(estimator1, X, y, sample_weight=sample_weight, **fit_params)\n",
    "\n",
    "    else:\n",
    "        return estimator\n",
    "\n",
    "\n",
    "class VotingClassifierLGBM(VotingClassifier):\n",
    "    def fit(self, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "\n",
    "        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n",
    "            raise NotImplementedError('Multilabel and multi-output'\n",
    "                                      ' classification is not supported.')\n",
    "\n",
    "        if self.voting not in ('soft', 'hard'):\n",
    "            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"\n",
    "                             % self.voting)\n",
    "\n",
    "        if self.estimators is None or len(self.estimators) == 0:\n",
    "            raise AttributeError('Invalid `estimators` attribute, `estimators`'\n",
    "                                 ' should be a list of (string, estimator)'\n",
    "                                 ' tuples')\n",
    "\n",
    "        if (self.weights is not None and\n",
    "                len(self.weights) != len(self.estimators)):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d estimators'\n",
    "                             % (len(self.weights), len(self.estimators)))\n",
    "\n",
    "        names, clfs = zip(*self.estimators)\n",
    "        self._validate_names(names)\n",
    "\n",
    "        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n",
    "        if n_isnone == len(self.estimators):\n",
    "            raise ValueError('All estimators are None. At least one is '\n",
    "                             'required to be a classifier!')\n",
    "\n",
    "        self.le_ = LabelEncoder().fit(y)\n",
    "        self.classes_ = self.le_.classes_\n",
    "        self.estimators_ = []\n",
    "\n",
    "        transformed_y = self.le_.transform(y)\n",
    "\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n",
    "                                             sample_weight=sample_weight, threshold=threshold, **fit_params)\n",
    "            for clf in clfs if clf is not None)\n",
    "\n",
    "        return self"
   ],
   "id": "1140cf6ad66ae9ab",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:38:31.664766Z",
     "start_time": "2024-07-10T06:38:31.526693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clfs = []\n",
    "for i in range(15):\n",
    "    clf = xgb.XGBClassifier(random_state=217 + i, n_estimators=300, learning_rate=0.15, n_jobs=4, **opt_parameters)\n",
    "\n",
    "    clfs.append(('xgb{}'.format(i), clf))\n",
    "\n",
    "vc = VotingClassifierLGBM(clfs, voting='soft')\n",
    "del (clfs)\n",
    "\n",
    "#Train the final model with learning rate decay\n",
    "_ = vc.fit(X_train.drop(xgb_drop_cols, axis=1), y_train, sample_weight=y_train_weights, threshold=False, **fit_params)\n",
    "\n",
    "clf_final = vc.estimators_[0]"
   ],
   "id": "89c92ad970463bae",
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAxisError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m(clfs)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m#Train the final model with learning rate decay\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m _ \u001B[38;5;241m=\u001B[39m vc\u001B[38;5;241m.\u001B[39mfit(X_train\u001B[38;5;241m.\u001B[39mdrop(xgb_drop_cols, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), y_train, sample_weight\u001B[38;5;241m=\u001B[39my_train_weights, threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m     13\u001B[0m clf_final \u001B[38;5;241m=\u001B[39m vc\u001B[38;5;241m.\u001B[39mestimators_[\u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[0;32mIn[20], line 84\u001B[0m, in \u001B[0;36mVotingClassifierLGBM.fit\u001B[0;34m(self, X, y, sample_weight, threshold, **fit_params)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_ \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     82\u001B[0m transformed_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mle_\u001B[38;5;241m.\u001B[39mtransform(y)\n\u001B[0;32m---> 84\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_ \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)(\n\u001B[1;32m     85\u001B[0m     delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n\u001B[1;32m     86\u001B[0m                                      sample_weight\u001B[38;5;241m=\u001B[39msample_weight, threshold\u001B[38;5;241m=\u001B[39mthreshold, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m clf \u001B[38;5;129;01min\u001B[39;00m clfs \u001B[38;5;28;01mif\u001B[39;00m clf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1077\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[1;32m   1078\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1082\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[1;32m   1083\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1085\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[1;32m   1086\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1088\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 901\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dispatch(tasks)\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mapply_async(batch, callback\u001B[38;5;241m=\u001B[39mcb)\n\u001B[1;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m ImmediateResult(func)\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m batch()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "Cell \u001B[0;32mIn[20], line 18\u001B[0m, in \u001B[0;36m_parallel_fit_estimator\u001B[0;34m(estimator1, X, y, sample_weight, threshold, **fit_params)\u001B[0m\n\u001B[1;32m     16\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 18\u001B[0m         _ \u001B[38;5;241m=\u001B[39m estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, sample_weight\u001B[38;5;241m=\u001B[39my_train_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(estimator1, ExtraTreesClassifier) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(estimator1, RandomForestClassifier):\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:730\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    728\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    729\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:1519\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[1;32m   1491\u001B[0m (\n\u001B[1;32m   1492\u001B[0m     model,\n\u001B[1;32m   1493\u001B[0m     metric,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1498\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[1;32m   1499\u001B[0m )\n\u001B[1;32m   1500\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[1;32m   1501\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[1;32m   1502\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     feature_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types,\n\u001B[1;32m   1517\u001B[0m )\n\u001B[0;32m-> 1519\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m train(\n\u001B[1;32m   1520\u001B[0m     params,\n\u001B[1;32m   1521\u001B[0m     train_dmatrix,\n\u001B[1;32m   1522\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_num_boosting_rounds(),\n\u001B[1;32m   1523\u001B[0m     evals\u001B[38;5;241m=\u001B[39mevals,\n\u001B[1;32m   1524\u001B[0m     early_stopping_rounds\u001B[38;5;241m=\u001B[39mearly_stopping_rounds,\n\u001B[1;32m   1525\u001B[0m     evals_result\u001B[38;5;241m=\u001B[39mevals_result,\n\u001B[1;32m   1526\u001B[0m     obj\u001B[38;5;241m=\u001B[39mobj,\n\u001B[1;32m   1527\u001B[0m     custom_metric\u001B[38;5;241m=\u001B[39mmetric,\n\u001B[1;32m   1528\u001B[0m     verbose_eval\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m   1529\u001B[0m     xgb_model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m   1530\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[1;32m   1531\u001B[0m )\n\u001B[1;32m   1533\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n\u001B[1;32m   1534\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m=\u001B[39m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:730\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    728\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    729\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/xgboost/training.py:182\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[1;32m    180\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    181\u001B[0m     bst\u001B[38;5;241m.\u001B[39mupdate(dtrain, i, obj)\n\u001B[0;32m--> 182\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[1;32m    183\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    185\u001B[0m bst \u001B[38;5;241m=\u001B[39m cb_container\u001B[38;5;241m.\u001B[39mafter_training(bst)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/xgboost/callback.py:238\u001B[0m, in \u001B[0;36mCallbackContainer.after_iteration\u001B[0;34m(self, model, epoch, dtrain, evals)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, name \u001B[38;5;129;01min\u001B[39;00m evals:\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m name\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset name should not contain `-`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 238\u001B[0m score: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39meval_set(evals, epoch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_margin)\n\u001B[1;32m    239\u001B[0m metric_score \u001B[38;5;241m=\u001B[39m _parse_eval_str(score)\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_history(metric_score, epoch)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:2139\u001B[0m, in \u001B[0;36mBooster.eval_set\u001B[0;34m(self, evals, iteration, feval, output_margin)\u001B[0m\n\u001B[1;32m   2137\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m feval \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m dmat, evname \u001B[38;5;129;01min\u001B[39;00m evals:\n\u001B[0;32m-> 2139\u001B[0m         feval_ret \u001B[38;5;241m=\u001B[39m feval(\n\u001B[1;32m   2140\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dmat, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, output_margin\u001B[38;5;241m=\u001B[39moutput_margin),\n\u001B[1;32m   2141\u001B[0m             dmat,\n\u001B[1;32m   2142\u001B[0m         )\n\u001B[1;32m   2143\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(feval_ret, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m   2144\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m feval_ret:\n\u001B[1;32m   2145\u001B[0m                 \u001B[38;5;66;03m# pylint: disable=consider-using-f-string\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[19], line 11\u001B[0m, in \u001B[0;36mevaluate_macroF1_lgb\u001B[0;34m(predictions, truth)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate_macroF1_lgb\u001B[39m(predictions, truth):\n\u001B[0;32m---> 11\u001B[0m     pred_labels \u001B[38;5;241m=\u001B[39m predictions\u001B[38;5;241m.\u001B[39margmax(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     12\u001B[0m     truth \u001B[38;5;241m=\u001B[39m truth\u001B[38;5;241m.\u001B[39mget_label()\n\u001B[1;32m     13\u001B[0m     f1 \u001B[38;5;241m=\u001B[39m f1_score(truth, pred_labels, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mAxisError\u001B[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:38:43.721543Z",
     "start_time": "2024-07-10T06:38:43.707107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "global_score = f1_score(y_test, clf_final.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "vc.voting = 'soft'\n",
    "global_score_soft = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "vc.voting = 'hard'\n",
    "global_score_hard = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a single LGBM Classifier: {:.4f}'.format(global_score))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_score_soft))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_score_hard))"
   ],
   "id": "5a6d22198bd93c51",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m global_score \u001B[38;5;241m=\u001B[39m f1_score(y_test, clf_final\u001B[38;5;241m.\u001B[39mpredict(X_test\u001B[38;5;241m.\u001B[39mdrop(xgb_drop_cols, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)), average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m vc\u001B[38;5;241m.\u001B[39mvoting \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msoft\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      3\u001B[0m global_score_soft \u001B[38;5;241m=\u001B[39m f1_score(y_test, vc\u001B[38;5;241m.\u001B[39mpredict(X_test\u001B[38;5;241m.\u001B[39mdrop(xgb_drop_cols, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)), average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'clf_final' is not defined"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:38:52.333145Z",
     "start_time": "2024-07-10T06:38:52.327887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, X_train.drop(xgb_drop_cols, axis=1),\n",
    "                                                          display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "\n",
    "drop_features"
   ],
   "id": "88a600c60fbc4efb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:39:01.765581Z",
     "start_time": "2024-07-10T06:39:01.754533Z"
    }
   },
   "cell_type": "code",
   "source": "ranked_features = feature_importance(clf_final, X_train.drop(xgb_drop_cols, axis=1))",
   "id": "c66090a62666a3dc",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m ranked_features \u001B[38;5;241m=\u001B[39m feature_importance(clf_final, X_train\u001B[38;5;241m.\u001B[39mdrop(xgb_drop_cols, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'clf_final' is not defined"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:39:24.224059Z",
     "start_time": "2024-07-10T06:39:24.221115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "et_drop_cols = ['agg18_age_MAX', 'agg18_age_MEAN', 'agg18_age_MIN', 'agg18_dis_MEAN',\n",
    "                'agg18_escolari_MAX', 'agg18_escolari_MEAN', 'agg18_escolari_MIN',\n",
    "                'agg18_estadocivil1_COUNT', 'agg18_estadocivil1_MEAN',\n",
    "                'agg18_estadocivil2_COUNT', 'agg18_estadocivil2_MEAN',\n",
    "                'agg18_estadocivil3_COUNT', 'agg18_estadocivil3_MEAN',\n",
    "                'agg18_estadocivil4_COUNT', 'agg18_estadocivil4_MEAN',\n",
    "                'agg18_estadocivil5_COUNT', 'agg18_estadocivil5_MEAN',\n",
    "                'agg18_estadocivil6_COUNT', 'agg18_estadocivil6_MEAN',\n",
    "                'agg18_estadocivil7_COUNT', 'agg18_estadocivil7_MEAN',\n",
    "                'agg18_parentesco10_COUNT', 'agg18_parentesco10_MEAN',\n",
    "                'agg18_parentesco11_COUNT', 'agg18_parentesco11_MEAN',\n",
    "                'agg18_parentesco12_COUNT', 'agg18_parentesco12_MEAN',\n",
    "                'agg18_parentesco1_COUNT', 'agg18_parentesco1_MEAN',\n",
    "                'agg18_parentesco2_COUNT', 'agg18_parentesco2_MEAN',\n",
    "                'agg18_parentesco3_COUNT', 'agg18_parentesco3_MEAN',\n",
    "                'agg18_parentesco4_COUNT', 'agg18_parentesco4_MEAN',\n",
    "                'agg18_parentesco5_COUNT', 'agg18_parentesco5_MEAN',\n",
    "                'agg18_parentesco6_COUNT', 'agg18_parentesco6_MEAN',\n",
    "                'agg18_parentesco7_COUNT', 'agg18_parentesco7_MEAN',\n",
    "                'agg18_parentesco8_COUNT', 'agg18_parentesco8_MEAN',\n",
    "                'agg18_parentesco9_COUNT', 'agg18_parentesco9_MEAN']\n",
    "\n",
    "et_drop_cols.extend([\"idhogar\", \"parentesco1\", 'fe_rent_per_person', 'fe_rent_per_room',\n",
    "                     'fe_tablet_adult_density', 'fe_tablet_density'])"
   ],
   "id": "f7473d82ebec94e3",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:39:45.675712Z",
     "start_time": "2024-07-10T06:39:33.647757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ets = []\n",
    "for i in range(10):\n",
    "    rf = RandomForestClassifier(max_depth=None, random_state=217 + i, n_jobs=4, n_estimators=700,\n",
    "                                min_impurity_decrease=1e-3, min_samples_leaf=2, verbose=0, class_weight=\"balanced\")\n",
    "    ets.append(('rf{}'.format(i), rf))\n",
    "\n",
    "vc2 = VotingClassifierLGBM(ets, voting='soft')\n",
    "_ = vc2.fit(X_train.drop(et_drop_cols, axis=1), y_train, threshold=False)"
   ],
   "id": "aa0c185a7a89bc65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8971976052018816\n",
      "Test F1: 0.4130162974280621\n",
      "Train F1: 0.899344601612763\n",
      "Test F1: 0.4355662026652593\n",
      "Train F1: 0.8868585341751569\n",
      "Test F1: 0.4064271389749889\n",
      "Train F1: 0.9007040382372216\n",
      "Test F1: 0.4473175901492684\n",
      "Train F1: 0.8796763152108867\n",
      "Test F1: 0.3987604043194966\n",
      "Train F1: 0.8914965603461805\n",
      "Test F1: 0.38763972806665137\n",
      "Train F1: 0.8878426990059689\n",
      "Test F1: 0.4187961132718414\n",
      "Train F1: 0.8940621650131415\n",
      "Test F1: 0.42426926358399086\n",
      "Train F1: 0.8965505171736871\n",
      "Test F1: 0.45484779430116773\n",
      "Train F1: 0.8986130680097624\n",
      "Test F1: 0.43800001933763977\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:39:54.976426Z",
     "start_time": "2024-07-10T06:39:53.866272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vc2.voting = 'soft'\n",
    "global_rf_score_soft = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "vc2.voting = 'hard'\n",
    "global_rf_score_hard = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print(\n",
    "    'Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_rf_score_soft))\n",
    "print(\n",
    "    'Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_rf_score_hard))"
   ],
   "id": "ae1808618fe289bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8826\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.9126\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:40:02.298583Z",
     "start_time": "2024-07-10T06:40:01.072390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vc2.voting = 'soft'\n",
    "global_rf_score_soft = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "vc2.voting = 'hard'\n",
    "global_rf_score_hard = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print(\n",
    "    'Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_rf_score_soft))\n",
    "print(\n",
    "    'Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_rf_score_hard))"
   ],
   "id": "74955d810384d812",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8826\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.9126\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:40:09.513213Z",
     "start_time": "2024-07-10T06:40:09.221839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc2.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, X_train.drop(et_drop_cols, axis=1),\n",
    "                                                          display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "\n",
    "drop_features"
   ],
   "id": "c338e34b27e53724",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parentesco_LE', 'rez_esc'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:40:22.804204Z",
     "start_time": "2024-07-10T06:40:22.801628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_voters(data, weights=[0.5, 0.5]):\n",
    "    vc.voting = \"soft\"\n",
    "    vc1_probs = vc.predict_proba(data.drop(xgb_drop_cols, axis=1))\n",
    "    vc2.voting = \"soft\"\n",
    "    vc2_probs = vc2.predict_proba(data.drop(et_drop_cols, axis=1))\n",
    "\n",
    "    final_vote = (vc1_probs * weights[0]) + (vc2_probs * weights[1])\n",
    "    predictions = np.argmax(final_vote, axis=1)\n",
    "\n",
    "    return predictions"
   ],
   "id": "16001a8c343b192d",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:40:30.438515Z",
     "start_time": "2024-07-10T06:40:29.833168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "combo_preds = combine_voters(X_test, weights=[0.5, 0.5])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ],
   "id": "bfd63f67372160e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034518828451882845"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:40:37.629132Z",
     "start_time": "2024-07-10T06:40:37.158984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "combo_preds = combine_voters(X_test, weights=[0.4, 0.6])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ],
   "id": "14ccf7bdeace4363",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034518828451882845"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:40:42.606068Z",
     "start_time": "2024-07-10T06:40:42.066978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "combo_preds = combine_voters(X_test, weights=[0.6, 0.4])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ],
   "id": "9f70de8eacf52edf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034518828451882845"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:40:47.523087Z",
     "start_time": "2024-07-10T06:40:47.518450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_subm = pd.DataFrame()\n",
    "y_subm['Id'] = test_ids"
   ],
   "id": "d812335a25928014",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:40:54.736444Z",
     "start_time": "2024-07-10T06:40:54.623852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vc.voting = 'soft'\n",
    "y_subm_lgb = y_subm.copy(deep=True)\n",
    "y_subm_lgb['Target'] = vc.predict(test.drop(xgb_drop_cols, axis=1)) + 1\n",
    "\n",
    "vc2.voting = 'soft'\n",
    "y_subm_rf = y_subm.copy(deep=True)\n",
    "y_subm_rf['Target'] = vc2.predict(test.drop(et_drop_cols, axis=1)) + 1\n",
    "\n",
    "y_subm_ens = y_subm.copy(deep=True)\n",
    "y_subm_ens['Target'] = combine_voters(test) + 1"
   ],
   "id": "2b16d99ce47549f3",
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAxisError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m vc\u001B[38;5;241m.\u001B[39mvoting \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msoft\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      2\u001B[0m y_subm_lgb \u001B[38;5;241m=\u001B[39m y_subm\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 3\u001B[0m y_subm_lgb[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTarget\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m vc\u001B[38;5;241m.\u001B[39mpredict(test\u001B[38;5;241m.\u001B[39mdrop(xgb_drop_cols, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m      5\u001B[0m vc2\u001B[38;5;241m.\u001B[39mvoting \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msoft\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      6\u001B[0m y_subm_rf \u001B[38;5;241m=\u001B[39m y_subm\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_voting.py:440\u001B[0m, in \u001B[0;36mVotingClassifier.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    438\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvoting \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msoft\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 440\u001B[0m     maj \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict_proba(X), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# 'hard' voting\u001B[39;00m\n\u001B[1;32m    443\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict(X)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1229\u001B[0m, in \u001B[0;36margmax\u001B[0;34m(a, axis, out, keepdims)\u001B[0m\n\u001B[1;32m   1142\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1143\u001B[0m \u001B[38;5;124;03mReturns the indices of the maximum values along an axis.\u001B[39;00m\n\u001B[1;32m   1144\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;124;03m(2, 1, 4)\u001B[39;00m\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1228\u001B[0m kwds \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkeepdims\u001B[39m\u001B[38;5;124m'\u001B[39m: keepdims} \u001B[38;5;28;01mif\u001B[39;00m keepdims \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39m_NoValue \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[0;32m-> 1229\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _wrapfunc(a, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124margmax\u001B[39m\u001B[38;5;124m'\u001B[39m, axis\u001B[38;5;241m=\u001B[39maxis, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59\u001B[0m, in \u001B[0;36m_wrapfunc\u001B[0;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m bound(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001B[39;00m\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001B[39;00m\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;66;03m# exception has a traceback chain.\u001B[39;00m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "\u001B[0;31mAxisError\u001B[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T06:41:00.895343Z",
     "start_time": "2024-07-10T06:41:00.880488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "sub_file_lgb = 'submission_soft_XGB_{:.4f}_{}.csv'.format(global_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "sub_file_rf = 'submission_soft_RF_{:.4f}_{}.csv'.format(global_rf_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "sub_file_ens = 'submission_ens_{:.4f}_{}.csv'.format(global_combo_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "\n",
    "y_subm_lgb.to_csv(sub_file_lgb, index=False)\n",
    "y_subm_rf.to_csv(sub_file_rf, index=False)\n",
    "y_subm_ens.to_csv(sub_file_ens, index=False)"
   ],
   "id": "3bfeb3e5e040b034",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'global_score_soft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datetime\n\u001B[1;32m      3\u001B[0m now \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mnow()\n\u001B[0;32m----> 5\u001B[0m sub_file_lgb \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubmission_soft_XGB_\u001B[39m\u001B[38;5;132;01m{:.4f}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(global_score_soft, \u001B[38;5;28mstr\u001B[39m(now\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m'\u001B[39m)))\n\u001B[1;32m      6\u001B[0m sub_file_rf \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubmission_soft_RF_\u001B[39m\u001B[38;5;132;01m{:.4f}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(global_rf_score_soft, \u001B[38;5;28mstr\u001B[39m(now\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m'\u001B[39m)))\n\u001B[1;32m      7\u001B[0m sub_file_ens \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubmission_ens_\u001B[39m\u001B[38;5;132;01m{:.4f}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(global_combo_score_soft, \u001B[38;5;28mstr\u001B[39m(now\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m'\u001B[39m)))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'global_score_soft' is not defined"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
