{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import trimesh\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
    "\n",
    "path = 'http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip'\n",
    "data_dir = tf.keras.utils.get_file('modelnet.zip', path, extract=True)\n",
    "data_dir = os.path.join(os.path.dirname(data_dir), 'ModelNet10')\n",
    "\n",
    "fig = plt.figure(figsize=(50, 5))\n",
    "for i in range(len(classes)):\n",
    "    mesh = trimesh.load(os.path.join(data_dir, classes[i] + '/train/' + classes[i] + '_0001.off'))\n",
    "\n",
    "    points = mesh.sample(4096)\n",
    "\n",
    "    ax = fig.add_subplot(1, 10, i + 1, projection='3d')\n",
    "    ax.set_title(classes[i], fontsize=30)\n",
    "    ax.scatter(points[:, 0], points[:, 1], points[:, 2], s=1, c='g')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import glob\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor', 'night_stand', 'sofa', 'table', 'toilet']\n",
    "\n",
    "path = \"http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\"\n",
    "data_dir = tf.keras.utils.get_file('modelnet.zip', path, extract=True)\n",
    "data_dir = os.path.join(os.path.dirname(data_dir), 'ModelNet10')\n",
    "\n",
    "\n",
    "def parse_dataset(num_points=2048):\n",
    "    train_points, train_labels = [], []\n",
    "    test_points, test_labels = [], []\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        folder = os.path.join(data_dir, classes[i])\n",
    "        print('데이터 읽기 : 부류 {}'.format(os.path.basename(folder)))\n",
    "        train_files = glob.glob(os.path.join(folder, 'train/*'))\n",
    "        test_files = glob.glob(os.path.join(folder, 'test/*'))\n",
    "\n",
    "        for f in train_files:\n",
    "            train_points.append(trimesh.load(f).sample(num_points))\n",
    "            train_labels.append(i)\n",
    "        for f in test_files:\n",
    "            test_points.append(trimesh.load(f).sample(num_points))\n",
    "            test_labels.append(i)\n",
    "    return (np.array(train_points), np.array(test_points), np.array(train_labels), np.array(test_labels))\n",
    "\n",
    "\n",
    "NUM_POINTS = 2048\n",
    "NUM_CLASSES = 10\n",
    "batch_siz = 32\n",
    "\n",
    "x_train, x_test, y_train, y_test = parse_dataset(NUM_POINTS)\n",
    "\n",
    "\n",
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding='valid')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation('relu')(x)\n",
    "\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation('relu')(x)\n",
    "\n",
    "\n",
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
    "\n",
    "\n",
    "def tnet(inputs, num_features):\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(num_features * num_features, kernel_initializer='zeros', bias_initializer=bias,\n",
    "                     activity_regularizer=reg)(x)\n",
    "\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
    "x = tnet(inputs, 3)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = tnet(x, 32)\n",
    "x = conv_bn(x, 32)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 512)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 128)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='pointnet')\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[\"sparse_categorical_accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "\n",
    "chosen = np.random.randint(0, len(x_test), 8)\n",
    "points = x_test[chosen]\n",
    "labels = y_test[chosen]\n",
    "\n",
    "preds = model.predict(points)\n",
    "preds = tf.math.argmax(preds, -1)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(2, 4, i + 1, projection='3d')\n",
    "    ax.scatter(points[i, :, 0], points[i, :, 1], points[i, :, 2], s=1, c='g')\n",
    "    ax.set_title('pred : {:}, GT : {:}'.format(classes[preds[i].numpy()], classes[labels[i]]), fontsize=16)\n",
    "    ax.set_axis_off()"
   ],
   "id": "66d881fe85f6fe17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
