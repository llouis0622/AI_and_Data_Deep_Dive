# 1. 주목

## 1. 고전 주목 알고리즘

- 특징 선택 : 쓸모가 많은 특징은 남기고 나머지는 제거하는 작업
- 돌출 맵 : 컬러 대비, 명암 대비, 방향 대비 맵을 결합해 돌출 맵 구성

## 2. 딥러닝의 주목

- 순환 신경망을 이용해 입력 영상에서 주목할 곳을 순차적으로 알아냄
- 자기 주목 : 영상을 구성하는 요소 상호 간 주목 결정

# 2. 순환 신경망과 주목

## 1. 순환 신경망 기초

- 순환 신경망 : 은닉 노드끼리 에지를 가짐
- 은닉층, 은닉층 사이에 가중치 추가 → 가중치 집합 이룸
- 장거리 의존 : 앞쪽 단어와 멀리 뒤에 있는 단어가 밀접하게 상호작용
- LSTM : 순환 신경망을 개조해 장거리 의존을 처리하는 능력 강화

## 2. query-key-value로 계산하는 주목

- 유사성 정보를 가중치로 사용해 value를 가중하여 합함

## 3. 주목을 반영한 seq2seq 모델

- 바다나우 주목 : 주목을 표현하는 문맥 벡터 추가 → 확장

# 3. 트랜스포머

## 1. 기본 구조

- 인코더 디코더 구조

## 2. 인코더 동작

- 단어 임베딩과 위치 인코딩
- 자기 주목
- Multi-head 주목
- 위치별 FF층
- 가중치

## 3. 디코더의 동작

- Masked MHA층
- 인코더와 연결된 MHA층
- 가중치

# 4. 비전 트랜스포머

## 1. 분류를 위한 트랜스포머

- ViT
- 코드 작성

# 5. 비전 트랜스포머 프로그래밍 실습

- 코드 작성

# 6. 트랜스포머의 특성

- 코드 작성