{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(\n",
    "    [[169, 70], [172, 68], [175, 78], [163, 58], [180, 80], [159, 76], [158, 52], [173, 69], [180, 75], [155, 50],\n",
    "     [187, 90], [170, 66]])\n",
    "\n",
    "m = np.mean(X, axis=0)\n",
    "cv = np.cov(X, rowvar=False)\n",
    "\n",
    "gen = np.random.multivariate_normal(m, cv, 5)\n",
    "\n",
    "print(gen)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "X = x_train[np.isin(y_train, [0])]\n",
    "X = X.reshape((X.shape[0], 28 * 28))\n",
    "\n",
    "m = np.mean(X, axis=0)\n",
    "cv = np.cov(X, rowvar=False)\n",
    "\n",
    "gen = np.random.multivariate_normal(m, cv, 5)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(gen[i].reshape((28, 28)), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ],
   "id": "b40b834ea219cce6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "X = x_train[np.isin(y_train, [0])]\n",
    "X = X.reshape((X.shape[0], 28 * 28))\n",
    "\n",
    "k = 8\n",
    "\n",
    "gm = GaussianMixture(n_components=k).fit(X)\n",
    "\n",
    "gen = gm.sample(n_samples=10)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(k):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(gm.means_[i].reshape((28, 28)), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(gen[0][i].reshape((28, 28)), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ],
   "id": "a7adad6a303c75ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "zdim = 32\n",
    "\n",
    "encoder_input = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', strides=(1, 1))(encoder_input)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=(1, 1))(x)\n",
    "x = Flatten()(x)\n",
    "encoder_output = Dense(zdim)(x)\n",
    "model_encoder = Model(encoder_input, encoder_output)\n",
    "\n",
    "decoder_input = Input(shape=(zdim,))\n",
    "x = Dense(3136)(decoder_input)\n",
    "x = Reshape((7, 7, 64))(x)\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides=(1, 1))(x)\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "x = Conv2DTranspose(1, (3, 3), activation='relu', padding='same', strides=(1, 1))(x)\n",
    "decoder_output = x\n",
    "model_decoder = Model(decoder_input, decoder_output)\n",
    "\n",
    "model_input = encoder_input\n",
    "model_output = model_decoder(encoder_output)\n",
    "model = Model(model_input, model_output)\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mse')\n",
    "model.fit(x_train, x_train, epochs=50, batch_size=128, shuffle=True, validation_data=(x_test, x_test))\n",
    "\n",
    "i = np.random.randint(x_test.shape[0])\n",
    "j = np.random.randint(x_test.shape[0])\n",
    "x = np.array((x_test[i], x_test[j]))\n",
    "z = model_encoder.predict(x)\n",
    "\n",
    "zz = np.zeros((11, zdim))\n",
    "alpha = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for i in range(11):\n",
    "    zz[i] = (1.0 - alpha[i]) * z[0] + alpha[i] * z[1]\n",
    "\n",
    "gen = model_decoder.predict(zz)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(11):\n",
    "    plt.subplot(1, 11, i + 1)\n",
    "    plt.imshow(gen[i].reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(str(alpha[i]))"
   ],
   "id": "48a0a577da37131"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, Conv2DTranspose, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "zdim = 32\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], zdim), mean=0.0, stddev=0.1)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "encoder_input = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', strides=(1, 1))(encoder_input)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=(1, 1))(x)\n",
    "x = Flatten()(x)\n",
    "z_mean = Dense(zdim)(x)\n",
    "z_log_var = Dense(zdim)(x)\n",
    "encoder_output = Lambda(sampling)([z_mean, z_log_var])\n",
    "model_encoder = Model(encoder_input, [z_mean, z_log_var, encoder_output])\n",
    "\n",
    "decoder_input = Input(shape=(zdim,))\n",
    "x = Dense(3136)(decoder_input)\n",
    "x = Reshape((7, 7, 64))(x)\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides=(1, 1))(x)\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "x = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same', strides=(1, 1))(x)\n",
    "decoder_output = x\n",
    "model_decoder = Model(decoder_input, decoder_output)\n",
    "\n",
    "model_input = encoder_input\n",
    "model_output = model_decoder(encoder_output)\n",
    "model = Model(model_input, model_output)\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(\n",
    "    tf.reduce_sum(keras.losses.binary_crossentropy(model_input, model_output), axis=(1, 2)))\n",
    "kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "total_loss = reconstruction_loss + kl_loss\n",
    "model.add_loss(total_loss)\n",
    "\n",
    "model.compile(optimizer='adam')\n",
    "model.fit(x_train, x_train, epochs=50, batch_size=128, validation_data=(x_test, x_test))\n",
    "\n",
    "i = np.random.randint(x_test.shape[0])\n",
    "j = np.random.randint(x_test.shape[0])\n",
    "x = np.array((x_test[i], x_test[j]))\n",
    "z = model_encoder.predict(x)[2]\n",
    "\n",
    "zz = np.zeros((11, zdim))\n",
    "alpha = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for i in range(11):\n",
    "    zz[i] = (1.0 - alpha[i]) * z[0] + alpha[i] * z[1]\n",
    "\n",
    "gen = model_decoder.predict(zz)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(11):\n",
    "    plt.subplot(1, 11, i + 1)\n",
    "    plt.imshow(gen[i].reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(str(alpha[i]))"
   ],
   "id": "5b0a06a981843806"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train[np.isin(y_train, [8])]\n",
    "x_train = (x_train.astype('float32') / 255.0) * 2.0 - 1.0\n",
    "\n",
    "zdim = 100\n",
    "\n",
    "\n",
    "def make_discriminator(in_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation=LeakyReLU(alpha=0.2), input_shape=in_shape))\n",
    "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(Conv2D(256, (3, 3), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_generator(zdim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7 * 7 * 64, activation=LeakyReLU(alpha=0.2), input_dim=zdim))\n",
    "    model.add(Reshape((7, 7, 64)))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(\n",
    "        Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(\n",
    "        Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(Conv2D(1, (3, 3), padding='same', activation='tanh'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_gan(G, D):\n",
    "    D.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(G)\n",
    "    model.add(D)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    x = dataset[ix]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def generate_latent_points(zdim, n_samples):\n",
    "    return np.random.randn(n_samples, zdim)\n",
    "\n",
    "\n",
    "def generate_fake_samples(G, zdim, n_samples):\n",
    "    x_input = generate_latent_points(zdim, n_samples)\n",
    "    x = G.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def train(G, D, GAN, dataset, zdim, n_epochs=200, batch_siz=128, verbose=0):\n",
    "    n_batch = int(dataset.shape[0] / batch_siz)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for b in range(n_batch):\n",
    "            x_real, y_real = generate_real_samples(dataset, batch_siz // 2)\n",
    "            d_loss1, _ = D.train_on_batch(x_real, y_real)\n",
    "            x_fake, y_fake = generate_fake_samples(G, zdim, batch_siz // 2)\n",
    "            d_loss2, _ = D.train_on_batch(x_fake, y_fake)\n",
    "\n",
    "            x_gan = generate_latent_points(zdim, batch_siz)\n",
    "            y_gan = np.ones((batch_siz, 1))\n",
    "            g_loss = GAN.train_on_batch(x_gan, y_gan)\n",
    "        if verbose == 1:\n",
    "            print('E%d : loss D(real) = %.3f, D(fake)%.3f GAN %.3f' % (epoch + 1, d_loss1, d_loss2, g_loss))\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            x_fake, y_fake = generate_fake_samples(G, zdim, 12)\n",
    "            plt.figure(figsize=(20, 2))\n",
    "            plt.suptitle('epoch ' + str(epoch + 1))\n",
    "            for k in range(12):\n",
    "                plt.subplot(1, 12, k + 1)\n",
    "                plt.imshow((x_fake[k] + 1) / 2.0, cmap='gray')\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "D = make_discriminator((28, 28, 1))\n",
    "G = make_generator(zdim)\n",
    "GAN = make_gan(G, D)\n",
    "train(G, D, GAN, x_train, zdim, verbose=1)"
   ],
   "id": "76d4be271d579358"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train[np.isin(y_train.reshape([y_train.shape[0]]), [1])]\n",
    "x_train = (x_train.astype('float32') / 255.0) * 2.0 - 1.0\n",
    "\n",
    "zdim = 100\n",
    "\n",
    "\n",
    "def make_discriminator(in_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation=LeakyReLU(alpha=0.2), input_shape=in_shape))\n",
    "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(Conv2D(256, (3, 3), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_generator(zdim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4 * 4 * 256, activation=LeakyReLU(alpha=0.2), input_dim=zdim))\n",
    "    model.add(Reshape((4, 4, 256)))\n",
    "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "    model.add(Conv2D(3, (3, 3), padding='same', activation='tanh'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_gan(G, D):\n",
    "    D.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(G)\n",
    "    model.add(D)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    x = dataset[ix]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def generate_latent_points(zdim, n_samples):\n",
    "    return np.random.randn(n_samples, zdim)\n",
    "\n",
    "\n",
    "def generate_fake_samples(G, zdim, n_samples):\n",
    "    x_input = generate_latent_points(zdim, n_samples)\n",
    "    x = G.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def train(G, D, GAN, dataset, zdim, n_epochs=200, batch_siz=128, verbose=0):\n",
    "    n_batch = int(dataset.shape[0] / batch_siz)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for b in range(n_batch):\n",
    "            x_real, y_real = generate_real_samples(dataset, batch_siz // 2)\n",
    "            d_loss1, _ = D.train_on_batch(x_real, y_real)\n",
    "            x_fake, y_fake = generate_fake_samples(G, zdim, batch_siz // 2)\n",
    "            d_loss2, _ = D.train_on_batch(x_fake, y_fake)\n",
    "\n",
    "            x_gan = generate_latent_points(zdim, batch_siz)\n",
    "            y_gan = np.ones((batch_siz, 1))\n",
    "            g_loss = GAN.train_on_batch(x_gan, y_gan)\n",
    "        if verbose == 1:\n",
    "            print('E%d : loss D(real) = %.3f, D(fake)%.3f GAN %.3f' % (epoch + 1, d_loss1, d_loss2, g_loss))\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            x_fake, y_fake = generate_fake_samples(G, zdim, 12)\n",
    "            plt.figure(figsize=(20, 2))\n",
    "            plt.suptitle('epoch ' + str(epoch + 1))\n",
    "            for k in range(12):\n",
    "                plt.subplot(1, 12, k + 1)\n",
    "                plt.imshow((x_fake[k] + 1) / 2.0, cmap='gray')\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "D = make_discriminator((32, 32, 3))\n",
    "G = make_generator(zdim)\n",
    "GAN = make_gan(G, D)\n",
    "train(G, D, GAN, x_train, zdim, verbose=1)"
   ],
   "id": "5ba85ae6dfe5b33a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import keras_cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = keras_cv.models.StableDiffusion(img_width=512, img_height=512)\n",
    "img = model.text_to_image('A cute rabbit in an avocado armchair', batch_size=3)\n",
    "\n",
    "for i in range(len(img)):\n",
    "    plt.subplot(1, len(img), i + 1)\n",
    "    plt.imshow(img[i])\n",
    "    plt.axis('off')"
   ],
   "id": "9922988fd07a45c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
